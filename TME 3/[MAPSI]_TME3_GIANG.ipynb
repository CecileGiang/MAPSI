{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etudiante: GIANG Phuong Thu, C√©cile (3530406)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage de param√®tres par maximum de vraisemblance\n",
    "Dans ce TME, l'objectif est d'apprendre gr√¢ce √† l'estimateur de maximum de vraisemblance les param√®tres de lois normales √† partir d'un ensemble de donn√©es. Ces lois normales seront ensuite exploit√©es pour faire de la classification (comme nous l'avions vu en cours avec les images de d√©sert, for√™t, mer et paysages enneig√©s).\n",
    "\n",
    "Ici, notre base de donn√©es d'apprentissage est la base USPS. Celle-ci contient les images r√©elles de chiffres provenant de codes postaux √©crits manuellement et scann√©s par le service des postes am√©ricain. Ces donn√©es scann√©es ont √©t√© normalis√©es de mani√®re √† ce qu'elles soient toutes des images de 16x16 pixels en teintes de gris, cf. Le Cun et al., 1990:\n",
    "\n",
    "Y. LeCun, O. Matan, B. Boser, J. S. Denker, et al. (1990) *Handwritten zip code recognition with multilayer networks*. In ICPR, volume II, pages 35‚Äì40.\n",
    "\n",
    "Voici quelques exemples d'images de cette base : \n",
    "\n",
    "<img src=\"usps.png\" title=\"Quelques exemples\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des donn√©es et premi√®res visualisations\n",
    "\n",
    "Nous utiliserons la librairie pickle qui permet de s√©rialiser les objets en python (ie, les sauver et les charger tr√®s facilement).\n",
    "Une fois les donn√©es charg√©es, nous allons √©tudier tr√®s rapidement la distribution des classes, visualiser une imagette de chiffre et comprendre l'encodage de ces chiffres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([488., 412., 311., 260., 306., 244., 261., 282., 224., 281.]),\n",
       " array([-0.5,  0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chargement des donn√©es\n",
    "data = pkl.load(open(\"usps.pkl\",'rb')) \n",
    "# data est un dictionnaire contenant les champs explicites X_train, X_test, Y_train, Y_test\n",
    "X_train = np.array(data[\"X_train\"],dtype=float) # changement de type pour √©viter les probl√®mes d'affichage\n",
    "X_test = np.array(data[\"X_test\"],dtype=float)\n",
    "Y_train = data[\"Y_train\"]\n",
    "Y_test = data[\"Y_test\"]\n",
    "\n",
    "# visualisation de la distribution des √©tiquettes (dans les 10 classes de chiffres)\n",
    "plt.figure()\n",
    "plt.hist(Y_train, np.linspace(-0.5,9.5,11))\n",
    "plt.hist(Y_test, np.linspace(-0.5,9.5,11))\n",
    "#plt.savefig(\"distr_classes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6229, 256)\n",
      "(3069, 256) (6229,) (3069,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image de : 6')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prise en main des matrices X, Y\n",
    "print(X_train.shape)\n",
    "# 6229 images compos√©es de 256 pixels (image = 16x16)\n",
    "print(X_test.shape,Y_train.shape, Y_test.shape)\n",
    "\n",
    "# Affichage de l'image 18 de la base de donn√©es et r√©cup√©ration de l'√©tiquette associ√©e:\n",
    "# (1) remise en forme de la ligne de 256 pixels en 16x16\n",
    "# (2) affichage avec imshow (en niveaux de gris)\n",
    "# (3) r√©cup√©ration de l'√©tiquette dans Y_train\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(X_train[18].reshape(16,16),cmap=\"gray\")\n",
    "plt.title(\"Image de : {}\".format(Y_train[18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 2.0\n",
      "niveaux de gris :  2001\n"
     ]
    }
   ],
   "source": [
    "# analyse des valeurs min et max, recherche du nombre de niveaux de gris dans les images:\n",
    "print(X_train.min(),X_train.max() )\n",
    "print(\"niveaux de gris : \", len(np.unique(X_train))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Apprentissage et √©valuation d'un mod√®le gaussien na√Øf\n",
    "\n",
    "## A1- Maximum de vraisemblance \n",
    "\n",
    "Nous allons √©tudier la distribution de probabilit√© des teintes de gris des images (en fait, nous allons √©tudier sa fonction de densit√© car on travaille sur des variables al√©atoires continues) . Nous allons faire l'hypoth√®se (certes un peu forte mais tellement pratique) que, dans chaque classe, les teintes des pixels sont mutuellement ind√©pendantes. \n",
    "\n",
    "Autrement dit, si $X_i, i\\in \\{0,...,255\\}$ repr√©sente la variable al√©atoire \"intensit√© de gris du i√®me pixel\", alors $p(X_0,‚Ä¶,X_{255})$ repr√©sente la fonction de densit√© des teintes de gris des images de la classe et: \n",
    "\n",
    "$$p(X_0,,‚Ä¶,X_{255})=\\prod_{i=0}^{255} p(X_i)$$\n",
    "\n",
    "Ainsi, en choisissant au hasard une image dans l'ensemble de toutes les images possibles de la classe, si celle-ci correspond au tableau `np.array([x_0,...,x_255])`, o√π les $x_i$ sont des nombres r√©els compris entre 0 et 2, alors la valeur de la fonction de densit√© de l'image est √©gale √† $p(x_0,...,x_{255}) = \\prod^{255}_{i=0}p(x_i)$. \n",
    "\n",
    "Nous allons de plus supposer que chaque $X_i$ suit une distribution normale de param√®tres $(Œº_i,œÉ^2_i)$. Autrement dit, $$\\forall i\\in\\{0,...,255\\}, X_i \\sim {\\cal N}(Œº_i,œÉ^2_i)$$ \n",
    "\n",
    "Par maximum de vraisemblance, estimez, pour une classe donn√©e, l'ensemble des param√®tres $(Œº_0,‚Ä¶,Œº_{255})$ et $(œÉ^2_0,‚Ä¶,œÉ^2_{255})$ pour chaque classe (chiffre de 0 √† 9). Pour cela, √©crivez une fonction `learnML_parameters : float np.array x float np.array -> float np.array x float np.array` qui, √©tant donn√© le tableau d'images , renvoie un couple de tableaux, le premier √©l√©ment du couple correspondant √† l'ensemble des $Œº_i$ et le 2√®me √† l'ensemble des $œÉ^2_i$. C'est-√†-dire que `learnML_parameters` renverra deux matrices:\n",
    "$$ mu \\in \\mathbb R^{10 \\times 256}, sig \\in \\mathbb R^{10 \\times 256}$$\n",
    "\n",
    "* mu contient les moyennes des 256 pixels pour les 10 classes\n",
    "* std contient les √©carts-types des 256 pixels pour les 10 classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnML_class_parameters( classe ):\n",
    "    \"\"\" Etant donn√© une classe d'images (i.e. un tableau d'images), retourne l'ensemble des param√®tres\n",
    "        (mu_0, mu_1, ..., mu_255) et (std_0, ..., std_255) correspondant aux param√®tres des lois normales suivies par\n",
    "        les Xi (Xi v.a d√©crivant l'intensit√© du i-i√®me pixel).\n",
    "        @param classe: float np.array np.array, tableau d'images correspondant √† une classe\n",
    "        @return liste_mu, liste_sigma: float np.array x float np.array, liste des mu_i et des sigma\n",
    "    \"\"\"\n",
    "    # ------- Liste des mu_i et des std_i\n",
    "    liste_mu = []\n",
    "    liste_std = []\n",
    "    \n",
    "    # ------- Calcul de liste_mu et liste_sigma\n",
    "    \n",
    "    for i in range(256):\n",
    "        mu_i = 0\n",
    "        std_i = 0\n",
    "        \n",
    "        # Calcul de mu_i\n",
    "        for image in classe:\n",
    "            mu_i += image[i]\n",
    "        \n",
    "        if len(classe)!=0:\n",
    "            mu_i = mu_i/len(classe)\n",
    "        \n",
    "        # Calcul de std_i: racine carr√© de la moyenne des √©carts √† la moyenne au carr√©\n",
    "        for image in classe:\n",
    "            std_i += (image[i] - mu_i)**2\n",
    "        \n",
    "        if len(classe)!=0:\n",
    "            std_i = np.sqrt(std_i/len(classe))\n",
    "        \n",
    "        # Mise √† jour de liste_mu et liste_sigma\n",
    "        liste_mu.append(mu_i)\n",
    "        liste_std.append(std_i)\n",
    "    \n",
    "    return (np.array(liste_mu), np.array(liste_std))\n",
    "\n",
    "def learnML_parameters(X,Y):\n",
    "    \"\"\" Etant donn√© un tableau d'images, retourne un couple de tableaux, correspondant √† (mu_0, mu_1, ..., mu_9) et \n",
    "        (std_0, ..., std_9), o√π chaque mu_i est l'ensemble des moyennes des pixels des images de classe i et chaque\n",
    "        std_i est l'ensemble des √©carts-types des 256 pixels pour les images de classe i.\n",
    "        Ce sont les param√®tres des lois normales suivies par les Xi (Xi v.a d√©crivant l'intensit√© du i-i√®me pixel).\n",
    "        @param X: float np.array, tableau d'images (i.e. tableau de tableaux de pixels)\n",
    "        @param Y: float np.array, tableau des classes: Y[i] contient la classe de l'image X[i]\n",
    "        @return mu, std: float np.array x float np.array, liste des mu_i et des std_i\n",
    "    \"\"\"\n",
    "    mu = []\n",
    "    std = []\n",
    "    \n",
    "    # Liste des classes 0 √† 9, chaque classe contient toutes les images de cette classe dans X\n",
    "    liste_classes = [[] for i in range(10)]\n",
    "    print(len(liste_classes))\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        liste_classes[Y[i]].append(X[i])\n",
    "    \n",
    "    for classe in liste_classes:\n",
    "        mu_i, std_i = learnML_class_parameters(classe)\n",
    "        mu.append(mu_i)\n",
    "        std.append(std_i)\n",
    "        \n",
    "    return (np.array(mu), np.array(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(10, 256) (10, 256)\n"
     ]
    }
   ],
   "source": [
    "mu,sig = learnML_parameters ( X_train, Y_train )\n",
    "print(mu.shape, sig.shape) # doit donner (10, 256) (10, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: pour la classe 0, les param√®tres doivent √™tre les suivants\n",
    "```\n",
    "mu[0]=\n",
    "[1.53774208e-03 4.46785940e-03 1.71216078e-02 6.31194048e-02\n",
    " 1.84061642e-01 4.71391665e-01 8.97640989e-01 1.15019928e+00\n",
    " ...\n",
    " 1.42675380e+00 1.03130694e+00 5.32240296e-01 1.74166387e-01\n",
    " 3.57644515e-02 5.52804884e-03 4.36592998e-04 0.00000000e+00]\n",
    "sig[0]=\n",
    "[5.01596286e-02 7.93695089e-02 1.46489017e-01 2.65522337e-01\n",
    " 4.42306204e-01 6.35148001e-01 7.40462105e-01 7.48387032e-01\n",
    " ...\n",
    " 6.62741331e-01 6.75677391e-01 5.86224763e-01 3.56460503e-01\n",
    " 1.71512333e-01 5.67475697e-02 1.20193571e-02 0.00000000e+00]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.53774208e-03 4.46785940e-03 1.71216078e-02 6.31194048e-02\n",
      " 1.84061642e-01 4.71391665e-01 8.97640989e-01 1.15019928e+00\n",
      " 1.02070900e+00 6.16785408e-01 2.50766353e-01 8.09903122e-02\n",
      " 1.49310824e-02 3.87033274e-03 1.70898437e-04 0.00000000e+00\n",
      " 2.35601434e-03 7.93762565e-03 5.18573940e-02 2.00940178e-01\n",
      " 5.59411980e-01 1.10202446e+00 1.53532559e+00 1.66378367e+00\n",
      " 1.60174400e+00 1.37845195e+00 9.19353768e-01 4.15479248e-01\n",
      " 1.22346858e-01 3.01527050e-02 4.24372534e-03 5.63428995e-06\n",
      " 5.88210737e-03 3.00679919e-02 1.45009354e-01 4.68428296e-01\n",
      " 9.87103163e-01 1.46020945e+00 1.63103905e+00 1.59445846e+00\n",
      " 1.52785712e+00 1.52155705e+00 1.36630499e+00 9.33882722e-01\n",
      " 4.29464169e-01 1.16865928e-01 2.02650169e-02 1.02089895e-03\n",
      " 7.91202062e-03 6.88018163e-02 3.30783411e-01 8.24194929e-01\n",
      " 1.31254975e+00 1.54256605e+00 1.44943446e+00 1.21191395e+00\n",
      " 1.09220056e+00 1.22655949e+00 1.39070742e+00 1.27821441e+00\n",
      " 8.46682745e-01 3.48925595e-01 8.07226924e-02 4.64439750e-03\n",
      " 1.59532081e-02 1.76675445e-01 6.07781794e-01 1.12757141e+00\n",
      " 1.46523519e+00 1.45472469e+00 1.13856317e+00 8.10338934e-01\n",
      " 6.26168286e-01 7.76955398e-01 1.10779727e+00 1.32851374e+00\n",
      " 1.16676063e+00 6.86548686e-01 2.41357803e-01 2.81289553e-02\n",
      " 4.81442913e-02 3.73752078e-01 8.81483647e-01 1.31949916e+00\n",
      " 1.46700523e+00 1.23718114e+00 8.16962582e-01 4.43474916e-01\n",
      " 2.80405642e-01 4.08021647e-01 7.81619032e-01 1.17122113e+00\n",
      " 1.27515733e+00 9.72332353e-01 4.74029267e-01 8.55221959e-02\n",
      " 1.30783142e-01 5.93982138e-01 1.07686306e+00 1.39894059e+00\n",
      " 1.36844099e+00 9.74245539e-01 5.33412071e-01 2.15832907e-01\n",
      " 1.06282689e-01 1.88639261e-01 5.18731675e-01 9.65949319e-01\n",
      " 1.24726249e+00 1.12132596e+00 6.89466858e-01 1.96154590e-01\n",
      " 2.50674651e-01 7.61315399e-01 1.19695898e+00 1.38864862e+00\n",
      " 1.19971341e+00 7.48517123e-01 3.30572606e-01 9.84733976e-02\n",
      " 4.29241342e-02 1.03367730e-01 3.87229277e-01 8.44056198e-01\n",
      " 1.20012881e+00 1.18425086e+00 8.20222630e-01 3.08674699e-01\n",
      " 3.58261634e-01 8.62190202e-01 1.25563738e+00 1.34673373e+00\n",
      " 1.07142879e+00 5.89123140e-01 1.96728277e-01 4.28680832e-02\n",
      " 1.60351829e-02 7.26840328e-02 3.45407532e-01 8.19457636e-01\n",
      " 1.19289312e+00 1.21496732e+00 8.84999523e-01 3.79906737e-01\n",
      " 3.87331813e-01 9.06482830e-01 1.29035945e+00 1.31940006e+00\n",
      " 9.78757769e-01 4.76966465e-01 1.27168587e-01 2.11923134e-02\n",
      " 1.44063591e-02 8.57732477e-02 3.76648466e-01 8.87929238e-01\n",
      " 1.23895217e+00 1.25035519e+00 8.86075297e-01 3.57954944e-01\n",
      " 3.26138273e-01 8.93522235e-01 1.31510628e+00 1.35238794e+00\n",
      " 9.61461921e-01 4.39577541e-01 1.13927428e-01 3.84975505e-02\n",
      " 5.36327846e-02 1.69787235e-01 5.42599817e-01 1.06182197e+00\n",
      " 1.37321399e+00 1.25057057e+00 8.18406790e-01 2.61721288e-01\n",
      " 1.82330468e-01 7.59475951e-01 1.28679207e+00 1.44958046e+00\n",
      " 1.10688967e+00 5.57203861e-01 2.14130381e-01 1.47069378e-01\n",
      " 2.15676089e-01 4.32815974e-01 8.96862446e-01 1.36377634e+00\n",
      " 1.49075578e+00 1.15939639e+00 6.22067020e-01 1.26992220e-01\n",
      " 5.84152687e-02 4.67427550e-01 1.09806340e+00 1.51210615e+00\n",
      " 1.42226714e+00 9.41197788e-01 5.57709665e-01 4.99719957e-01\n",
      " 6.56042283e-01 1.00399766e+00 1.40647827e+00 1.61266601e+00\n",
      " 1.41656614e+00 8.81148097e-01 3.21861387e-01 3.67738419e-02\n",
      " 1.09871555e-02 1.48898601e-01 6.49790437e-01 1.29661503e+00\n",
      " 1.64543706e+00 1.56182002e+00 1.31738978e+00 1.25782812e+00\n",
      " 1.39819160e+00 1.60791875e+00 1.72751589e+00 1.54867872e+00\n",
      " 1.01832667e+00 4.19518357e-01 9.27781289e-02 7.52478765e-03\n",
      " 2.67797390e-03 2.13532309e-02 1.63836169e-01 6.27896414e-01\n",
      " 1.26470542e+00 1.69852879e+00 1.80189263e+00 1.79891885e+00\n",
      " 1.80963883e+00 1.76736086e+00 1.51130342e+00 9.40219832e-01\n",
      " 3.74622653e-01 8.96866275e-02 1.24228554e-02 1.88855453e-03\n",
      " 7.41913845e-05 1.44583295e-03 1.03138830e-02 7.97420072e-02\n",
      " 3.19437704e-01 7.96441981e-01 1.28306524e+00 1.52049088e+00\n",
      " 1.42675380e+00 1.03130694e+00 5.32240296e-01 1.74166387e-01\n",
      " 3.57644515e-02 5.52804884e-03 4.36592998e-04 0.00000000e+00] [5.01596286e-02 7.93695089e-02 1.46489017e-01 2.65522337e-01\n",
      " 4.42306204e-01 6.35148001e-01 7.40462105e-01 7.48387032e-01\n",
      " 7.52036960e-01 6.78162781e-01 4.81813622e-01 2.95993695e-01\n",
      " 1.02298252e-01 6.82956225e-02 3.69197145e-03 0.00000000e+00\n",
      " 5.53305148e-02 9.36063684e-02 2.40012769e-01 4.83422217e-01\n",
      " 7.27502091e-01 8.01985000e-01 6.94079513e-01 6.09677496e-01\n",
      " 6.52843815e-01 7.58749067e-01 8.06674659e-01 6.41779078e-01\n",
      " 3.75508554e-01 1.82421873e-01 5.60909703e-02 1.83784976e-04\n",
      " 9.07390154e-02 1.92883673e-01 4.16989953e-01 7.07690582e-01\n",
      " 8.35158840e-01 7.30403526e-01 6.28008151e-01 6.32851408e-01\n",
      " 6.86100539e-01 6.71979869e-01 7.51457414e-01 8.24431822e-01\n",
      " 6.63627535e-01 3.74208629e-01 1.38194178e-01 2.98619157e-02\n",
      " 9.45533790e-02 2.82750058e-01 6.06158973e-01 8.42184682e-01\n",
      " 8.02525637e-01 6.80684430e-01 7.48069966e-01 8.29618901e-01\n",
      " 8.54595560e-01 8.13916791e-01 7.25657326e-01 7.80928249e-01\n",
      " 8.29105508e-01 6.20032814e-01 3.01234018e-01 5.58154512e-02\n",
      " 1.09365871e-01 4.41834837e-01 7.86403336e-01 8.54671841e-01\n",
      " 7.25871029e-01 7.49769833e-01 8.60018826e-01 8.48475760e-01\n",
      " 7.93461173e-01 8.30151279e-01 8.38238904e-01 7.46830716e-01\n",
      " 8.23250136e-01 8.07749355e-01 5.21476656e-01 1.51179416e-01\n",
      " 1.93296940e-01 6.43519638e-01 8.66847326e-01 7.99175192e-01\n",
      " 7.32236741e-01 8.36613090e-01 8.58973603e-01 7.10036806e-01\n",
      " 5.93002877e-01 6.76919355e-01 8.31300490e-01 8.22357229e-01\n",
      " 7.87742805e-01 8.57211603e-01 7.19108684e-01 2.69220701e-01\n",
      " 3.32313804e-01 7.92583272e-01 8.69718115e-01 7.69382790e-01\n",
      " 7.94654102e-01 8.64282887e-01 7.76566173e-01 5.26547832e-01\n",
      " 3.76112150e-01 4.76751198e-01 7.55143627e-01 8.53824054e-01\n",
      " 7.91149389e-01 8.39106726e-01 8.31564203e-01 4.23639743e-01\n",
      " 4.87032030e-01 8.63470062e-01 8.47748200e-01 7.72816355e-01\n",
      " 8.52947815e-01 8.56126914e-01 6.26520525e-01 3.57070009e-01\n",
      " 2.32239243e-01 3.50765435e-01 6.85159974e-01 8.53280525e-01\n",
      " 8.21682300e-01 8.23020619e-01 8.73898674e-01 5.52603454e-01\n",
      " 6.01596881e-01 8.84913792e-01 8.23667880e-01 7.97195327e-01\n",
      " 8.79116478e-01 8.04003126e-01 4.88515527e-01 2.33873563e-01\n",
      " 1.32954990e-01 2.82824021e-01 6.47546729e-01 8.55150837e-01\n",
      " 8.32743227e-01 8.13760126e-01 8.79500639e-01 6.23278481e-01\n",
      " 6.27274788e-01 8.87553616e-01 8.08346650e-01 7.99217941e-01\n",
      " 8.83241286e-01 7.40576048e-01 3.95873214e-01 1.58194876e-01\n",
      " 1.35774498e-01 3.17394838e-01 6.64478692e-01 8.69441926e-01\n",
      " 8.24799842e-01 8.14857118e-01 8.75637883e-01 5.99084617e-01\n",
      " 5.60878494e-01 8.79172781e-01 7.99994274e-01 7.79500355e-01\n",
      " 8.71300238e-01 7.07469723e-01 3.70424796e-01 2.22900094e-01\n",
      " 2.61840203e-01 4.53336326e-01 7.48030848e-01 8.66036662e-01\n",
      " 7.69580365e-01 8.21516759e-01 8.58901592e-01 4.99634590e-01\n",
      " 3.90619385e-01 8.34941475e-01 8.17641589e-01 7.24679551e-01\n",
      " 8.40919298e-01 7.59144096e-01 5.11722843e-01 4.41270048e-01\n",
      " 5.16084855e-01 6.84294249e-01 8.42083832e-01 7.76860627e-01\n",
      " 7.07485281e-01 8.39049325e-01 7.73085343e-01 3.34022719e-01\n",
      " 2.04963592e-01 6.81793854e-01 8.40705264e-01 6.82730699e-01\n",
      " 7.26315544e-01 8.23864229e-01 7.46543700e-01 7.28041059e-01\n",
      " 7.90768951e-01 8.23062208e-01 7.65169592e-01 6.35267424e-01\n",
      " 7.38940651e-01 8.33830774e-01 5.75147368e-01 1.70537311e-01\n",
      " 9.87858616e-02 3.81298193e-01 7.51553287e-01 7.80270482e-01\n",
      " 5.63772865e-01 6.42284817e-01 7.48036762e-01 7.75665140e-01\n",
      " 7.32949180e-01 6.31842594e-01 5.10614267e-01 6.55642504e-01\n",
      " 8.07719344e-01 6.34404155e-01 3.08036725e-01 7.70031201e-02\n",
      " 4.28491533e-02 1.49241169e-01 3.88664918e-01 7.09137364e-01\n",
      " 7.47600259e-01 5.37788720e-01 4.69614715e-01 4.75974793e-01\n",
      " 4.70450663e-01 5.17338109e-01 6.74591782e-01 7.68727058e-01\n",
      " 5.82843252e-01 2.99680167e-01 9.71493362e-02 5.02788596e-02\n",
      " 2.30063923e-03 3.19935119e-02 8.28517967e-02 2.53333160e-01\n",
      " 4.80454805e-01 6.58647918e-01 6.69771998e-01 6.43217647e-01\n",
      " 6.62741331e-01 6.75677391e-01 5.86224763e-01 3.56460503e-01\n",
      " 1.71512333e-01 5.67475697e-02 1.20193571e-02 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(mu[0], sig[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons bien les r√©sultats attendus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2- Log-vraisemblance d'une image pour une classe\n",
    "\n",
    "√âcrivez une fonction `log_likelihood : float np.array x float np.array x float np.array -> float` qui, √©tant donn√© une image (donc un tableau de 256 nombres r√©els) et un couple de param√®tres `( array ( [Œº0,‚Ä¶,Œº255] ), array ( [œÉ20,‚Ä¶,œÉ255] ) )`, renvoie la log-vraisemblance qu'aurait l'image selon cet ensemble de $Œº_i$ et $œÉ_i$ (correspondant √† une classe de chiffre). Rappelez-vous que (en mettant $-\\frac{1}{2}$ en facteur) : \n",
    "\n",
    "$$\\log(p(x_0,\\cdots,x_{255})=\\sum_{i=0}^{255} \\log p(x_i)=-\\frac{1}{2}\\sum_{i=0}^{255} \\left[ \\log(2\\pi \\sigma^2_i) + \\frac{(x_i-\\mu_i)^2}{\\sigma_i^2} \\right]$$\n",
    "\n",
    "Notez que le module `np` contient une constante `np.pi` ainsi que toutes les fonctions math√©matiques classiques directement applicables sur des vecteurs. Vous pouvez donc √©ventuellement coder la ligne pr√©c√©dente sans boucle, en une ligne.\n",
    "\n",
    "**Attention**: dans la matrice `sig` calcul√©e dans la question pr√©c√©dente, pour certains pixels de certaines classes, la valeur de $œÉ^2$ est √©gale √† $0$ (toutes les images de la base d'apprentissage avaient exactement la m√™me valeur sur ce pixel). \n",
    "* cette valeur pose probl√®me dans le calcul pr√©c√©dent (division par 0)\n",
    "* R√©fl√©chir √† diff√©rente mani√®re de traiter ce probl√®me:\n",
    " * faible valeur par d√©faut de $\\sigma$ refl√©tant une variance tr√®s faible mais √©vitant la division par 0 (usage de  `np.maximum`par exemple)\n",
    " * vraisemblance de 1 pour le ou les pixels impact√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on utilisera dans la suite le param√®tre defeps: \n",
    "#    positif, il donne la valeur minimale d'√©cart type\n",
    "#    = -1, il faut prendre une vraisemblance de 1 pour les pixels concern√©s\n",
    "\n",
    "import math\n",
    "\n",
    "def log_likelihood(image, mu, sigma, defsig = 1e-5):\n",
    "    \"\"\" Etant donn√© une image et un couple de param√®tres  (liste_mu, liste_sigma_2), renvoie la log-vraisemblance qu'aurait\n",
    "        l'image selon cet ensemble de mu_i, sigma_i.\n",
    "        @param image: float np.array, tableau de flottants correspondant aux pixels d'une image\n",
    "        @param (mu, sigma): (float np.array, np.array), couple de param√®tres (liste_mu, liste_sigma_2) contenant les param√®tres\n",
    "                        des lois normales suivies par chaque pixel de l'image\n",
    "        @return log: float, log-vraisemblance de l'image\n",
    "    \"\"\"\n",
    "    # Variable contenant la valeur du log de vraisemblance\n",
    "    log = 0\n",
    "    \n",
    "    for i in range(256):\n",
    "        \n",
    "        # Dans le cas o√π sigma = 0, la vraisemblance est √©gale √† 1 et donc log = 0\n",
    "        if sigma[i] == 0 :\n",
    "            if defsig >= 0:\n",
    "                sigma_i = defsig\n",
    "            else:\n",
    "                sigma_i = 1\n",
    "        else:\n",
    "            sigma_i = sigma[i]\n",
    "        \n",
    "        if sigma_i != 1:\n",
    "            log_1  = np.log((2 * math.pi * (sigma_i**2)))\n",
    "            log_2 = ((image[i] - mu[i])**2 ) / (sigma_i**2)\n",
    "            log += -(1/2) * (log_1 + log_2)\n",
    "            \n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test de la fonction `log_likelihood` avec `defsig = 1e-5`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-90.69963035168726\n",
      "[-90.69963035168726, -231211311074.53247, -364.83171019852006, -487.01085544875855, -513.1280647451548, -387.7594698419803, -59610.11773361824, -75567222244.77467, -271.98054261638936, -857252055.4774216]\n"
     ]
    }
   ],
   "source": [
    "print(log_likelihood(X_train[0], mu[0], sig[0])) \n",
    "# vraisemblance de l'image 0 selon les param√®tres de la classe 0\n",
    "\n",
    "print([log_likelihood(X_train[0], mu[i], sig[i],) for i in range(10)]) \n",
    "# vraisemblance de l'image 0 pour toutes les classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test de la fonction `log_likelihood` avec `defsig = -1`: la vraisemblance est de 1 et donc le log_vraisemblance est de 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-111.88760421521835\n",
      "[-111.88760421521835, -1716629080.989729, -364.83171019852006, -487.01085544875855, -544.9100255404516, -387.7594698419803, -59747.8395637312, -581523.2639945432, -303.762503411686, -13497.825910916881]\n"
     ]
    }
   ],
   "source": [
    "print(log_likelihood(X_train[0], mu[0], sig[0],-1)) \n",
    "# vraisemblance de l'image 0 selon les param√®tres de la classe 0\n",
    "\n",
    "print([log_likelihood(X_train[0], mu[i], sig[i],-1) for i in range(10)]) \n",
    "# vraisemblance de l'image 0 pour toutes les classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check : le code ci-dessus avec une valeur par d√©faut de $1e-5$ pour les sigmas nuls doit donner:\n",
    "```\n",
    "-90.69963035168726\n",
    "```\n",
    "puis pour toutes les classes:\n",
    "```\n",
    "[-90.69963035168726, -231211311074.5327, -364.8317101985202, -487.01085544875843, -513.128064745155, -387.75946984198, -59610.117733618186, -75567222244.77489, -271.980542616389, -857252055.4774221]\n",
    "```\n",
    "\n",
    "Avec une vraisemblance de 1 pour les pixels probl√©matiques:\n",
    "```\n",
    "[-111.88760421521835, -1716629080.989729, -364.83171019852006, -487.01085544875855, -544.9100255404516, -387.7594698419803, -59747.8395637312, -581523.2639945432, -303.762503411686, -13497.825910916881]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3- Classification d'une image\n",
    "√âcrire une fonction `classify_image : float np.array x float np.array x float np.array -> int` qui, √©tant donn√©e une image et l'ensemble de param√®tres d√©termin√©s dans les questions pr√©c√©dentes, renvoie la classe la plus probable de l'image, c'est-√†-dire celle dont la log-vraisemblance est la plus grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On √©crit d'abord une fonction qui rend les log-vraisemblances d'une image pour toutes les classes possibles (0 √† 9)\n",
    "\n",
    "def log_likelihoods(image, mu, sigma, defsig = 1e-5):\n",
    "    \"\"\" Etant donn√© une image et une liste de couples de param√®tres telle que d√©termin√©e dans la question 3, renvoie \n",
    "        le tableau des log-vraisemblances qu'aurait l'image selon la classe (entre 0 et 9).\n",
    "        @param image: float np.array, tableau de flottants correspondant aux pixels d'une image\n",
    "        @param (mu, sigma): (float np.array, np.array) list, liste de couples de param√®tres (mu, std) \n",
    "                             contenant les param√®tres des lois normales suivies par chaque pixel de l'image\n",
    "        @return liste_logs: float np.array, tableau des log-vraisemblances de l'image selon chaque classe\n",
    "    \"\"\"\n",
    "    return np.array( [log_likelihood(image, mu[i], sig[i], defsig) for i in range(10)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image, mu, sig, defsig=1e-5):\n",
    "    \"\"\" Etant donn√© une image et une liste de couples de caram√®tres comme d√©termin√© dans les questions pr√©c√©dentes, renvoie\n",
    "        la classe la plus probable de l'image, i.e. celle dont la log-vraisemblance est la plus grande.\n",
    "        @param image: float np.array, tableau de flottants correspondant aux pixels d'une image\n",
    "        @param liste_params: (float np.array, np.array) list, liste de couples de param√®tres (liste_mu, liste_sigma_2) \n",
    "                             contenant les param√®tres des lois normales suivies par chaque pixel de l'image\n",
    "        @return : int, classe la plus probable de l'image\n",
    "    \"\"\"\n",
    "    return np.argmax(log_likelihoods(image, mu, sig, defsig=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On teste la fonction `classify_image` avec une image de classe 0:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "classify_image(X_train[0], mu, sig, -1)\n",
    "# l'image 0 est de la classe 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous retrouvons bien la valeur obtenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4- Classification de toutes les images\n",
    "√âcrire une fonction `classify_all_images : float np.array x float np.array x float np.array -> float np.array` qui, √©tant donn√© un tableau $X$ des images ($N \\times 256$) et l'ensemble de param√®tres d√©termin√©s dans les questions pr√©c√©dentes, renvoie un tableau $\\hat Y$ qui donne la pr√©diction de classe pour toutes les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_all_images(X, mu, sig, defsig=1e-5):\n",
    "    \"\"\" Etant donn√© un tableau  ùëã  des images ( ùëÅ√ó256 ) et l'ensemble de param√®tres d√©termin√©s dans les questions \n",
    "        pr√©c√©dentes, renvoie un tableau  ùëåÃÇ qui donne la pr√©diction de classe pour toutes les images.\n",
    "        float np.array x float np.array x float np.array -> float np.array\n",
    "    \"\"\"\n",
    "    prediction = []\n",
    "    for image in X:\n",
    "        prediction.append(classify_image(image, mu, sig, defsig=1e-5))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test de la fonction `classify_all_images` sur `X_train`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 7, 8, 2, 5, 6, 0, 9, 0, 7, 6, 0, 6, 6, 5, 2, 1, 6, 9, 0, 6, 5, 9, 8, 4, 0, 7, 6, 5, 4, 4, 2, 7, 6, 6, 6, 2, 1, 1, 8, 1, 1, 6, 0, 3, 1, 1, 8, 0, 7, 2, 5, 0, 2, 9, 1, 2, 0, 8, 6, 0, 6, 9, 7, 7, 9, 1, 3, 6, 1, 0, 0, 6, 6, 2, 1, 3, 9, 0, 0, 5, 9, 6, 2, 1, 0, 1, 0, 8, 3, 9, 0, 7, 1, 5, 0, 0, 0, 2, 6, 8, 1, 7, 9, 3, 0, 7, 2, 2, 0, 0, 1, 8, 2, 0, 0, 1, 9, 0, 9, 3, 7, 1, 1, 8, 5, 0, 0, 9, 0, 1, 2, 1, 7, 1, 9, 1, 0, 3, 6, 6, 6, 6, 7, 0, 8, 2, 8, 2, 0, 1, 7, 9, 0, 2, 0, 3, 8, 0, 7, 7, 0, 8, 8, 1, 8, 2, 8, 5, 7, 2, 7, 0, 8, 0, 2, 6, 6, 0, 1, 0, 9, 2, 9, 9, 1, 3, 1, 0, 5, 1, 9, 2, 4, 0, 2, 1, 0, 3, 9, 1, 7, 9, 9, 7, 0, 7, 1, 9, 1, 0, 9, 9, 6, 1, 2, 1, 0, 7, 1, 8, 0, 3, 1, 9, 2, 0, 8, 9, 6, 7, 8, 0, 6, 9, 1, 9, 9, 3, 7, 7, 8, 6, 1, 9, 9, 7, 1, 6, 7, 9, 3, 3, 1, 8, 2, 8, 8, 2, 9, 8, 8, 6, 7, 1, 7, 1, 5, 4, 2, 9, 8, 0, 9, 0, 1, 1, 6, 2, 9, 0, 7, 9, 5, 6, 3, 7, 6, 2, 8, 8, 1, 0, 6, 9, 3, 6, 0, 2, 0, 9, 0, 5, 0, 0, 1, 1, 6, 8, 2, 6, 0, 6, 6, 1, 7, 7, 8, 8, 0, 6, 3, 1, 1, 2, 2, 7, 0, 8, 0, 2, 2, 8, 0, 6, 7, 6, 9, 1, 7, 6, 6, 1, 9, 1, 9, 1, 1, 6, 7, 6, 1, 0, 3, 7, 7, 1, 3, 7, 6, 6, 7, 0, 1, 9, 9, 7, 5, 8, 7, 9, 0, 9, 1, 7, 1, 2, 7, 6, 1, 6, 6, 3, 5, 3, 9, 4, 9, 2, 9, 7, 0, 6, 3, 7, 4, 6, 1, 9, 4, 0, 1, 8, 9, 4, 1, 8, 1, 8, 8, 1, 2, 7, 0, 6, 0, 8, 0, 4, 9, 6, 7, 2, 9, 7, 7, 0, 3, 8, 1, 2, 9, 0, 2, 6, 4, 9, 5, 8, 2, 1, 5, 1, 2, 1, 3, 9, 6, 6, 1, 5, 0, 6, 0, 5, 1, 9, 1, 2, 7, 8, 0, 9, 9, 7, 6, 1, 0, 8, 3, 7, 6, 6, 1, 7, 9, 3, 7, 9, 8, 6, 0, 8, 9, 2, 7, 0, 3, 9, 6, 6, 8, 1, 7, 8, 9, 1, 7, 0, 8, 6, 0, 2, 0, 3, 7, 2, 0, 3, 0, 1, 7, 1, 2, 1, 7, 2, 1, 7, 7, 7, 8, 4, 2, 8, 0, 6, 9, 6, 1, 8, 1, 6, 2, 2, 6, 0, 1, 8, 3, 6, 0, 2, 7, 9, 1, 0, 0, 2, 9, 3, 1, 7, 0, 9, 1, 0, 1, 7, 9, 1, 8, 1, 6, 5, 6, 0, 8, 2, 8, 1, 8, 9, 8, 0, 1, 3, 3, 3, 7, 8, 7, 5, 2, 7, 9, 4, 6, 4, 0, 7, 0, 8, 1, 2, 6, 7, 9, 2, 8, 4, 2, 6, 6, 6, 0, 4, 9, 6, 8, 9, 4, 6, 9, 0, 9, 7, 6, 7, 0, 9, 0, 6, 5, 2, 8, 6, 8, 7, 2, 5, 0, 7, 7, 7, 8, 2, 7, 0, 0, 1, 2, 9, 9, 8, 7, 4, 1, 7, 6, 0, 8, 1, 2, 9, 8, 1, 0, 3, 7, 6, 0, 2, 0, 3, 3, 9, 1, 7, 7, 5, 6, 8, 7, 9, 1, 0, 9, 5, 6, 7, 6, 9, 0, 2, 4, 1, 7, 1, 1, 5, 6, 1, 7, 7, 0, 8, 6, 1, 3, 4, 9, 9, 7, 6, 8, 6, 2, 7, 7, 9, 5, 0, 7, 6, 6, 0, 0, 7, 1, 8, 6, 6, 2, 1, 1, 5, 7, 3, 8, 6, 6, 7, 7, 1, 7, 8, 6, 1, 7, 6, 0, 7, 3, 1, 5, 3, 2, 7, 9, 0, 6, 4, 9, 7, 2, 0, 8, 7, 9, 2, 7, 7, 0, 1, 9, 6, 3, 6, 0, 1, 6, 6, 8, 7, 7, 1, 7, 2, 0, 6, 0, 1, 3, 2, 3, 8, 8, 1, 1, 8, 7, 1, 0, 9, 9, 6, 3, 2, 9, 7, 6, 6, 8, 8, 3, 7, 6, 9, 7, 8, 6, 5, 5, 6, 1, 1, 6, 6, 5, 0, 0, 8, 1, 7, 7, 3, 9, 0, 5, 0, 1, 6, 6, 1, 0, 1, 1, 6, 8, 8, 0, 5, 7, 8, 7, 3, 5, 7, 0, 8, 9, 1, 9, 7, 0, 2, 8, 4, 7, 9, 9, 6, 6, 2, 6, 3, 6, 9, 1, 7, 1, 9, 7, 7, 7, 0, 6, 0, 1, 4, 7, 7, 5, 0, 0, 7, 9, 6, 0, 8, 8, 9, 2, 3, 2, 2, 1, 7, 0, 8, 3, 3, 5, 0, 1, 9, 0, 1, 0, 0, 1, 1, 7, 6, 0, 7, 0, 0, 2, 9, 2, 3, 9, 5, 9, 7, 0, 6, 4, 8, 5, 1, 3, 6, 9, 1, 0, 1, 6, 0, 9, 7, 2, 4, 8, 2, 0, 6, 0, 0, 1, 7, 0, 0, 1, 1, 0, 0, 5, 7, 5, 0, 1, 0, 7, 0, 6, 7, 6, 6, 8, 8, 6, 7, 7, 6, 0, 9, 1, 0, 8, 1, 1, 4, 3, 5, 7, 7, 1, 2, 5, 5, 2, 6, 0, 9, 1, 8, 0, 7, 9, 9, 6, 2, 8, 8, 0, 2, 8, 8, 0, 1, 7, 1, 9, 6, 0, 9, 0, 0, 0, 9, 9, 6, 8, 1, 9, 4, 0, 7, 7, 3, 2, 1, 0, 7, 8, 9, 7, 1, 3, 9, 6, 1, 9, 0, 7, 3, 9, 9, 9, 1, 7, 8, 7, 1, 8, 7, 3, 6, 1, 1, 0, 2, 8, 5, 7, 2, 7, 0, 0, 6, 7, 0, 0, 6, 7, 4, 2, 2, 0, 8, 7, 9, 8, 3, 5, 6, 8, 1, 0, 1, 9, 8, 9, 1, 7, 0, 1, 1, 0, 1, 6, 5, 9, 9, 2, 6, 2, 6, 3, 6, 8, 0, 5, 3, 8, 6, 3, 7, 1, 7, 6, 9, 3, 6, 2, 6, 0, 1, 9, 7, 1, 4, 3, 1, 6, 6, 1, 9, 0, 5, 1, 7, 2, 8, 5, 7, 1, 2, 9, 9, 0, 6, 6, 5, 9, 6, 3, 1, 7, 7, 1, 8, 3, 9, 8, 1, 6, 2, 8, 4, 2, 9, 7, 6, 8, 6, 7, 6, 9, 4, 1, 0, 8, 5, 7, 9, 6, 4, 0, 6, 6, 8, 5, 7, 0, 6, 0, 9, 7, 2, 7, 1, 9, 6, 6, 5, 9, 0, 7, 1, 7, 3, 1, 6, 8, 8, 3, 8, 6, 1, 0, 1, 1, 6, 7, 1, 0, 8, 8, 9, 9, 5, 7, 7, 0, 8, 9, 4, 2, 1, 6, 7, 1, 8, 6, 3, 1, 3, 2, 7, 9, 7, 8, 9, 6, 1, 5, 7, 0, 8, 6, 1, 9, 6, 1, 5, 7, 8, 9, 7, 1, 0, 0, 6, 8, 7, 6, 9, 7, 1, 0, 7, 3, 0, 8, 7, 1, 2, 6, 7, 9, 5, 6, 2, 9, 6, 1, 1, 6, 0, 2, 9, 4, 3, 5, 6, 6, 7, 2, 0, 9, 1, 2, 5, 6, 2, 7, 2, 7, 1, 0, 8, 3, 0, 5, 1, 5, 7, 6, 0, 4, 1, 8, 5, 0, 2, 7, 7, 1, 2, 1, 7, 6, 6, 5, 6, 2, 6, 6, 2, 1, 1, 6, 2, 1, 1, 2, 1, 9, 8, 4, 4, 1, 8, 9, 0, 9, 0, 9, 2, 6, 0, 8, 0, 1, 2, 9, 9, 2, 1, 6, 5, 3, 9, 1, 6, 3, 1, 7, 6, 8, 9, 6, 7, 7, 1, 5, 1, 4, 0, 6, 8, 9, 1, 7, 2, 9, 6, 0, 1, 1, 8, 9, 7, 3, 3, 2, 1, 3, 8, 0, 1, 7, 9, 0, 8, 8, 7, 6, 9, 9, 2, 9, 4, 3, 2, 3, 9, 6, 2, 3, 9, 7, 4, 7, 9, 7, 1, 3, 5, 9, 9, 7, 7, 7, 2, 7, 8, 7, 1, 5, 7, 7, 0, 8, 9, 7, 7, 8, 5, 6, 7, 1, 7, 3, 8, 7, 5, 6, 7, 4, 9, 7, 1, 1, 7, 7, 7, 0, 1, 0, 0, 1, 0, 6, 5, 9, 9, 6, 7, 3, 9, 1, 6, 6, 3, 0, 2, 0, 1, 5, 0, 0, 9, 0, 3, 2, 8, 3, 7, 5, 8, 0, 1, 1, 8, 6, 6, 0, 1, 7, 1, 9, 6, 6, 1, 9, 9, 7, 8, 9, 7, 7, 1, 6, 0, 0, 0, 2, 4, 1, 2, 1, 0, 8, 3, 6, 6, 6, 9, 0, 2, 7, 5, 2, 0, 9, 0, 8, 9, 4, 7, 0, 0, 0, 0, 8, 2, 0, 7, 9, 7, 6, 9, 6, 2, 1, 7, 3, 1, 6, 7, 6, 0, 7, 6, 3, 6, 1, 1, 1, 6, 8, 7, 6, 0, 9, 1, 6, 6, 6, 6, 0, 5, 9, 7, 7, 3, 6, 9, 0, 1, 6, 0, 0, 6, 2, 8, 2, 0, 6, 5, 1, 0, 9, 1, 6, 4, 1, 0, 1, 0, 0, 0, 6, 1, 1, 6, 9, 3, 2, 7, 1, 0, 9, 1, 0, 6, 7, 8, 5, 1, 8, 1, 9, 3, 1, 7, 7, 2, 1, 3, 7, 2, 6, 4, 6, 1, 0, 5, 9, 9, 2, 0, 9, 2, 3, 7, 3, 0, 3, 8, 1, 0, 9, 1, 6, 3, 9, 6, 1, 1, 6, 2, 8, 1, 7, 6, 3, 1, 5, 2, 5, 1, 6, 8, 6, 1, 6, 0, 0, 5, 7, 3, 2, 6, 6, 2, 1, 1, 3, 6, 7, 2, 6, 2, 6, 7, 8, 2, 6, 2, 1, 8, 7, 7, 0, 0, 9, 8, 1, 6, 8, 9, 8, 0, 0, 1, 1, 7, 8, 8, 0, 7, 7, 8, 6, 0, 8, 4, 6, 1, 6, 5, 2, 2, 9, 6, 5, 7, 7, 1, 1, 2, 8, 9, 8, 1, 9, 6, 6, 6, 0, 9, 8, 2, 7, 6, 3, 3, 6, 5, 8, 0, 1, 9, 6, 7, 7, 9, 0, 4, 6, 8, 7, 6, 0, 0, 8, 1, 9, 0, 7, 1, 6, 7, 8, 0, 1, 1, 0, 0, 4, 7, 9, 7, 7, 9, 7, 0, 0, 6, 7, 1, 8, 6, 8, 1, 8, 7, 6, 0, 2, 2, 8, 7, 2, 1, 1, 1, 9, 2, 1, 4, 0, 2, 1, 3, 8, 2, 6, 1, 2, 2, 7, 3, 1, 3, 3, 1, 8, 2, 0, 0, 8, 1, 1, 0, 7, 1, 7, 1, 7, 2, 6, 8, 5, 1, 7, 1, 0, 8, 7, 7, 7, 2, 5, 5, 0, 8, 2, 7, 5, 1, 6, 1, 9, 0, 8, 7, 6, 0, 6, 9, 6, 1, 1, 1, 7, 7, 0, 0, 8, 5, 1, 9, 7, 3, 8, 6, 8, 1, 7, 9, 0, 8, 7, 8, 7, 1, 3, 9, 0, 8, 8, 7, 8, 8, 8, 0, 1, 5, 0, 7, 0, 1, 7, 6, 2, 1, 1, 6, 0, 4, 0, 9, 6, 6, 7, 1, 1, 6, 1, 8, 1, 7, 0, 3, 0, 7, 7, 8, 7, 2, 5, 3, 3, 7, 9, 0, 1, 4, 0, 6, 1, 5, 7, 1, 6, 1, 1, 7, 9, 1, 6, 8, 7, 2, 1, 9, 1, 9, 3, 7, 2, 0, 5, 0, 2, 7, 5, 2, 5, 9, 0, 2, 0, 3, 9, 0, 1, 1, 9, 0, 5, 7, 7, 4, 3, 3, 7, 1, 2, 0, 0, 8, 6, 1, 1, 2, 1, 3, 7, 8, 5, 9, 0, 9, 8, 1, 6, 7, 1, 7, 5, 7, 1, 1, 1, 5, 1, 1, 9, 8, 0, 3, 4, 2, 9, 1, 0, 1, 7, 0, 1, 3, 6, 0, 3, 2, 8, 6, 6, 7, 3, 6, 1, 9, 7, 4, 9, 1, 6, 8, 8, 1, 7, 6, 3, 7, 9, 6, 0, 4, 9, 2, 1, 8, 1, 8, 6, 5, 3, 0, 0, 8, 3, 1, 2, 0, 8, 0, 1, 7, 1, 7, 2, 1, 6, 3, 6, 6, 8, 2, 2, 1, 6, 6, 9, 7, 7, 9, 9, 6, 7, 7, 0, 1, 8, 9, 3, 6, 9, 9, 6, 1, 9, 0, 9, 1, 6, 1, 8, 9, 8, 7, 1, 9, 7, 1, 5, 8, 7, 8, 9, 3, 2, 0, 0, 2, 7, 1, 6, 4, 3, 9, 6, 2, 9, 0, 8, 6, 4, 3, 1, 1, 1, 3, 1, 2, 7, 9, 2, 6, 1, 8, 6, 9, 6, 9, 6, 6, 2, 0, 1, 6, 1, 9, 0, 1, 0, 7, 8, 2, 3, 6, 6, 0, 6, 7, 0, 6, 9, 1, 0, 2, 8, 7, 0, 0, 1, 6, 2, 8, 2, 1, 2, 5, 1, 0, 8, 6, 8, 9, 8, 2, 7, 5, 1, 0, 1, 1, 9, 6, 3, 0, 5, 9, 1, 8, 0, 8, 8, 9, 7, 0, 8, 5, 6, 0, 3, 1, 0, 8, 0, 4, 6, 2, 6, 7, 0, 7, 9, 7, 1, 6, 7, 7, 1, 7, 7, 7, 2, 7, 2, 6, 0, 9, 2, 4, 1, 1, 7, 0, 6, 2, 2, 1, 7, 3, 9, 7, 5, 9, 5, 0, 1, 4, 1, 1, 0, 3, 2, 2, 0, 6, 8, 9, 0, 8, 0, 6, 3, 7, 7, 0, 0, 9, 5, 8, 0, 1, 9, 4, 9, 9, 4, 0, 6, 1, 3, 9, 1, 6, 0, 0, 1, 2, 5, 5, 2, 2, 0, 1, 1, 1, 7, 7, 7, 1, 6, 6, 8, 9, 1, 6, 7, 0, 3, 3, 4, 6, 7, 3, 4, 2, 6, 6, 2, 7, 1, 1, 0, 6, 2, 9, 8, 9, 6, 1, 6, 3, 3, 9, 3, 6, 6, 0, 1, 1, 5, 0, 0, 0, 1, 2, 0, 3, 0, 7, 6, 8, 3, 1, 9, 1, 6, 5, 2, 0, 6, 2, 6, 6, 9, 3, 8, 4, 8, 8, 8, 0, 0, 7, 7, 6, 9, 7, 7, 2, 1, 8, 2, 8, 0, 9, 8, 7, 9, 3, 6, 7, 0, 1, 7, 0, 8, 2, 1, 6, 9, 7, 7, 8, 9, 0, 3, 0, 1, 8, 2, 9, 0, 9, 7, 0, 7, 3, 7, 1, 4, 3, 7, 2, 6, 9, 2, 7, 7, 9, 8, 3, 1, 9, 1, 1, 0, 9, 7, 7, 1, 6, 1, 0, 1, 6, 0, 0, 1, 2, 0, 7, 0, 8, 7, 1, 3, 0, 0, 8, 6, 6, 1, 4, 0, 8, 6, 3, 1, 7, 6, 8, 4, 7, 0, 1, 0, 1, 2, 8, 9, 9, 7, 9, 3, 9, 3, 6, 6, 0, 6, 5, 1, 7, 7, 9, 9, 2, 0, 2, 5, 6, 2, 8, 0, 9, 0, 0, 8, 6, 0, 7, 8, 9, 9, 6, 1, 7, 0, 8, 3, 9, 7, 1, 8, 5, 0, 8, 6, 6, 8, 0, 1, 9, 6, 9, 7, 0, 7, 9, 1, 5, 0, 9, 5, 9, 5, 0, 7, 7, 0, 7, 2, 8, 2, 1, 2, 1, 7, 5, 9, 1, 9, 2, 1, 9, 6, 6, 1, 1, 1, 1, 8, 0, 6, 9, 2, 6, 3, 1, 1, 6, 0, 1, 7, 8, 2, 6, 0, 7, 0, 0, 7, 6, 1, 6, 7, 9, 9, 2, 0, 2, 2, 1, 0, 5, 0, 6, 7, 0, 0, 9, 8, 0, 9, 8, 8, 4, 0, 0, 3, 1, 6, 6, 9, 6, 2, 6, 0, 7, 9, 0, 1, 1, 9, 5, 0, 7, 0, 2, 7, 6, 9, 8, 2, 6, 8, 6, 9, 7, 3, 3, 0, 5, 6, 8, 6, 9, 7, 7, 8, 3, 1, 9, 7, 7, 1, 7, 0, 8, 5, 7, 9, 2, 6, 1, 5, 1, 6, 6, 3, 6, 0, 8, 4, 9, 6, 1, 9, 6, 6, 7, 6, 6, 3, 1, 7, 0, 0, 6, 5, 9, 9, 0, 6, 8, 0, 0, 8, 1, 6, 1, 6, 0, 6, 8, 3, 6, 8, 9, 5, 3, 6, 8, 6, 6, 7, 2, 1, 6, 2, 8, 6, 0, 0, 1, 7, 1, 1, 5, 7, 2, 0, 6, 0, 9, 9, 6, 1, 0, 0, 7, 9, 3, 9, 9, 6, 3, 9, 2, 1, 6, 6, 7, 0, 6, 0, 9, 9, 6, 8, 1, 2, 1, 0, 8, 1, 1, 9, 0, 1, 8, 3, 9, 1, 6, 5, 6, 0, 1, 6, 7, 7, 6, 9, 8, 0, 5, 2, 3, 3, 3, 1, 5, 1, 7, 3, 0, 0, 6, 2, 4, 0, 1, 2, 9, 9, 0, 9, 0, 1, 0, 9, 6, 9, 9, 9, 8, 8, 0, 9, 1, 0, 4, 2, 5, 9, 7, 7, 1, 5, 7, 7, 9, 7, 3, 0, 0, 8, 0, 6, 1, 6, 7, 7, 5, 6, 0, 1, 3, 3, 8, 9, 3, 8, 5, 2, 2, 7, 7, 6, 7, 0, 3, 9, 3, 1, 9, 1, 5, 0, 7, 0, 9, 0, 2, 1, 9, 6, 0, 9, 9, 6, 2, 1, 1, 7, 8, 6, 1, 1, 0, 1, 7, 0, 1, 7, 8, 0, 9, 6, 1, 8, 3, 1, 0, 1, 0, 1, 2, 1, 7, 9, 1, 0, 1, 7, 3, 3, 7, 6, 0, 1, 7, 3, 8, 3, 0, 2, 9, 0, 6, 9, 4, 7, 9, 4, 3, 6, 2, 3, 9, 7, 8, 9, 5, 2, 9, 1, 0, 3, 9, 9, 2, 6, 0, 0, 0, 7, 7, 6, 6, 2, 0, 2, 0, 3, 8, 2, 0, 0, 0, 0, 7, 7, 9, 9, 1, 0, 6, 3, 8, 1, 0, 6, 6, 0, 9, 2, 8, 1, 1, 6, 7, 0, 1, 7, 7, 6, 2, 3, 4, 6, 1, 8, 9, 7, 1, 2, 0, 9, 6, 0, 5, 7, 9, 3, 9, 5, 8, 1, 6, 1, 0, 1, 6, 8, 8, 7, 0, 2, 9, 1, 1, 9, 2, 8, 7, 3, 5, 2, 0, 7, 7, 8, 0, 6, 7, 1, 0, 7, 0, 3, 7, 9, 1, 2, 9, 1, 8, 6, 0, 2, 9, 6, 8, 1, 7, 6, 8, 8, 5, 1, 3, 0, 0, 7, 9, 6, 2, 7, 8, 7, 4, 0, 7, 1, 0, 0, 7, 6, 9, 7, 1, 7, 1, 8, 6, 3, 8, 6, 1, 3, 0, 6, 0, 7, 7, 0, 7, 8, 7, 7, 4, 9, 6, 9, 0, 8, 4, 6, 9, 0, 7, 2, 0, 3, 6, 1, 8, 1, 0, 3, 0, 0, 6, 6, 6, 0, 6, 1, 0, 2, 0, 4, 1, 3, 9, 6, 3, 6, 2, 7, 0, 4, 2, 8, 4, 7, 0, 2, 1, 9, 0, 7, 8, 0, 0, 0, 9, 7, 9, 2, 6, 0, 1, 8, 1, 2, 5, 9, 8, 5, 0, 1, 3, 0, 9, 7, 8, 0, 9, 0, 0, 9, 7, 6, 6, 7, 6, 0, 2, 0, 7, 5, 6, 3, 8, 9, 1, 7, 8, 8, 6, 0, 7, 1, 0, 7, 6, 6, 0, 2, 1, 1, 0, 2, 7, 1, 6, 0, 1, 1, 3, 7, 2, 7, 1, 9, 2, 1, 8, 7, 0, 4, 9, 0, 8, 5, 1, 7, 9, 1, 8, 1, 3, 2, 7, 6, 1, 1, 1, 6, 1, 0, 6, 1, 4, 0, 1, 0, 7, 2, 1, 5, 1, 9, 1, 8, 3, 7, 6, 2, 8, 9, 0, 2, 2, 0, 7, 5, 8, 6, 7, 2, 7, 1, 8, 8, 6, 0, 5, 7, 0, 2, 7, 0, 6, 0, 7, 0, 0, 6, 8, 3, 7, 9, 7, 6, 1, 7, 0, 3, 7, 8, 1, 7, 0, 8, 9, 0, 9, 7, 2, 5, 5, 2, 0, 4, 3, 9, 2, 7, 8, 6, 7, 7, 1, 6, 4, 1, 8, 8, 6, 1, 2, 7, 9, 0, 0, 8, 7, 0, 3, 0, 8, 8, 9, 8, 8, 9, 8, 6, 0, 1, 2, 7, 1, 0, 1, 0, 7, 1, 9, 6, 5, 7, 9, 3, 2, 6, 1, 7, 5, 7, 1, 2, 1, 6, 0, 9, 2, 6, 1, 7, 9, 0, 1, 5, 9, 1, 8, 3, 6, 7, 6, 4, 1, 8, 8, 9, 5, 2, 9, 2, 1, 5, 2, 2, 0, 6, 8, 2, 0, 1, 2, 2, 1, 7, 2, 5, 9, 1, 0, 9, 0, 9, 8, 3, 4, 4, 6, 1, 0, 2, 9, 4, 2, 7, 9, 6, 3, 0, 6, 0, 0, 1, 1, 7, 8, 0, 8, 5, 9, 9, 1, 0, 0, 8, 7, 0, 1, 5, 9, 7, 6, 6, 9, 1, 0, 6, 0, 7, 6, 1, 0, 1, 1, 1, 0, 1, 3, 0, 0, 6, 2, 6, 6, 1, 5, 6, 9, 9, 4, 5, 5, 5, 7, 6, 2, 0, 1, 1, 7, 0, 6, 6, 7, 6, 8, 3, 8, 7, 5, 6, 0, 6, 9, 9, 0, 9, 8, 7, 0, 2, 2, 7, 8, 6, 7, 3, 6, 8, 9, 1, 2, 2, 8, 6, 1, 1, 7, 3, 0, 0, 4, 8, 6, 6, 1, 8, 7, 6, 8, 8, 0, 9, 3, 8, 1, 1, 8, 1, 7, 0, 8, 8, 0, 0, 5, 7, 7, 8, 8, 1, 9, 8, 6, 7, 8, 9, 1, 0, 1, 1, 6, 6, 6, 4, 0, 4, 2, 6, 2, 8, 6, 5, 9, 9, 2, 1, 1, 1, 9, 9, 6, 0, 6, 4, 0, 8, 2, 6, 8, 7, 8, 9, 2, 3, 8, 8, 7, 8, 0, 9, 7, 3, 2, 2, 9, 3, 2, 7, 0, 7, 6, 2, 0, 0, 1, 0, 1, 1, 0, 9, 7, 4, 0, 1, 6, 9, 1, 7, 6, 1, 2, 2, 1, 3, 1, 2, 8, 0, 9, 7, 6, 9, 0, 6, 1, 6, 1, 6, 9, 9, 6, 6, 9, 6, 0, 9, 7, 6, 0, 3, 7, 6, 7, 7, 9, 0, 3, 0, 0, 9, 9, 0, 0, 7, 6, 4, 5, 0, 7, 8, 1, 2, 2, 1, 3, 2, 1, 1, 5, 9, 7, 8, 9, 8, 1, 1, 1, 3, 1, 8, 1, 0, 6, 9, 0, 1, 1, 2, 8, 6, 1, 6, 5, 1, 9, 7, 6, 2, 8, 6, 8, 9, 6, 0, 0, 4, 7, 9, 0, 0, 2, 7, 2, 5, 8, 8, 8, 8, 3, 7, 0, 3, 3, 9, 1, 1, 9, 6, 7, 2, 2, 1, 6, 8, 8, 8, 0, 7, 4, 9, 7, 9, 0, 7, 7, 2, 2, 3, 7, 5, 0, 7, 1, 3, 6, 8, 9, 9, 8, 9, 1, 9, 1, 6, 1, 0, 0, 7, 9, 8, 5, 3, 7, 1, 0, 6, 0, 1, 5, 6, 9, 3, 1, 7, 2, 6, 6, 5, 1, 1, 7, 1, 0, 9, 1, 1, 2, 7, 6, 7, 1, 9, 6, 1, 0, 5, 3, 8, 0, 1, 0, 0, 8, 0, 1, 1, 4, 5, 2, 1, 0, 9, 1, 7, 0, 8, 0, 9, 8, 9, 1, 9, 2, 9, 1, 6, 9, 7, 9, 1, 5, 7, 4, 1, 8, 9, 9, 7, 4, 2, 0, 0, 0, 5, 6, 0, 1, 3, 1, 6, 6, 1, 1, 9, 6, 3, 1, 1, 9, 7, 6, 9, 3, 1, 6, 0, 2, 1, 8, 8, 6, 7, 7, 8, 6, 0, 1, 1, 0, 0, 0, 3, 9, 5, 6, 9, 1, 1, 6, 0, 6, 6, 4, 6, 6, 9, 5, 1, 0, 7, 0, 7, 7, 5, 9, 1, 7, 4, 8, 3, 7, 9, 3, 8, 0, 2, 7, 9, 0, 6, 5, 8, 8, 6, 6, 0, 6, 9, 1, 4, 4, 2, 8, 1, 7, 2, 1, 8, 7, 8, 7, 1, 0, 2, 0, 8, 2, 7, 6, 3, 0, 0, 1, 8, 6, 0, 9, 9, 0, 8, 8, 1, 0, 6, 6, 7, 6, 6, 1, 0, 7, 0, 8, 4, 5, 6, 7, 1, 6, 6, 6, 0, 9, 8, 7, 2, 0, 0, 6, 1, 7, 6, 9, 7, 1, 7, 6, 3, 2, 1, 5, 1, 0, 0, 7, 7, 0, 9, 7, 8, 5, 6, 1, 6, 6, 1, 2, 2, 9, 7, 0, 3, 2, 9, 2, 9, 2, 7, 3, 5, 1, 9, 1, 0, 9, 0, 1, 1, 9, 2, 6, 0, 9, 8, 0, 6, 4, 7, 4, 6, 5, 6, 1, 8, 6, 6, 4, 0, 1, 9, 1, 8, 1, 7, 1, 3, 1, 9, 3, 1, 6, 1, 0, 7, 6, 4, 0, 0, 8, 5, 0, 1, 7, 0, 0, 1, 1, 0, 1, 6, 4, 6, 6, 0, 1, 1, 4, 9, 5, 1, 2, 1, 7, 7, 5, 4, 6, 9, 9, 1, 0, 5, 6, 8, 6, 2, 8, 7, 2, 9, 7, 7, 0, 2, 6, 9, 9, 0, 8, 3, 3, 6, 8, 3, 7, 0, 9, 0, 9, 2, 8, 1, 8, 1, 3, 2, 7, 6, 2, 1, 9, 8, 8, 8, 1, 9, 9, 1, 7, 1, 6, 1, 1, 9, 0, 2, 1, 2, 7, 3, 2, 9, 2, 9, 1, 7, 2, 1, 8, 1, 9, 0, 1, 4, 1, 6, 8, 1, 2, 1, 2, 8, 2, 1, 9, 7, 7, 9, 8, 6, 3, 0, 9, 1, 2, 3, 1, 8, 3, 0, 0, 0, 1, 6, 2, 3, 0, 7, 1, 0, 1, 8, 1, 0, 8, 9, 8, 8, 2, 5, 1, 7, 2, 5, 7, 9, 9, 1, 4, 0, 9, 8, 8, 6, 8, 1, 9, 0, 0, 0, 3, 2, 8, 0, 6, 0, 0, 0, 5, 1, 6, 6, 0, 8, 8, 6, 0, 7, 4, 0, 8, 6, 2, 4, 2, 9, 9, 6, 6, 9, 6, 2, 6, 2, 6, 7, 3, 8, 2, 6, 6, 3, 0, 0, 0, 9, 0, 1, 9, 5, 9, 8, 0, 5, 5, 9, 1, 6, 2, 1, 9, 8, 5, 1, 7, 7, 8, 8, 2, 5, 3, 6, 3, 0, 0, 1, 7, 7, 4, 1, 0, 6, 8, 9, 9, 0, 0, 7, 2, 0, 2, 6, 8, 6, 8, 2, 4, 7, 9, 1, 7, 3, 6, 8, 7, 2, 9, 6, 1, 9, 3, 9, 9, 0, 0, 6, 7, 2, 8, 7, 5, 7, 9, 0, 1, 7, 2, 6, 1, 6, 7, 1, 9, 8, 0, 1, 6, 1, 7, 7, 9, 1, 0, 6, 6, 0, 5, 6, 6, 0, 7, 6, 7, 9, 9, 2, 7, 9, 7, 3, 0, 0, 1, 2, 0, 2, 9, 1, 0, 9, 8, 9, 1, 7, 6, 9, 0, 0, 5, 6, 7, 6, 3, 3, 1, 8, 0, 9, 1, 0, 7, 7, 1, 0, 2, 0, 6, 7, 0, 8, 3, 0, 1, 3, 9, 7, 1, 3, 5, 3, 2, 9, 0, 1, 1, 7, 9, 0, 0, 8, 7, 1, 7, 9, 7, 8, 7, 7, 0, 2, 9, 1, 9, 4, 7, 9, 9, 7, 1, 7, 3, 1, 2, 1, 7, 7, 6, 6, 5, 1, 7, 0, 8, 0, 7, 2, 3, 6, 0, 7, 5, 4, 9, 0, 2, 6, 9, 7, 9, 9, 7, 1, 0, 9, 1, 7, 1, 2, 6, 6, 3, 6, 7, 7, 1, 6, 7, 9, 7, 9, 1, 3, 4, 6, 2, 3, 2, 5, 0, 1, 6, 9, 5, 2, 0, 6, 8, 1, 8, 7, 1, 6, 1, 1, 7, 0, 1, 7, 6, 3, 7, 5, 1, 7, 1, 0, 2, 4, 9, 4, 2, 1, 4, 0, 9, 2, 7, 8, 8, 9, 9, 9, 7, 1, 7, 8, 0, 7, 6, 8, 1, 8, 0, 0, 7, 9, 0, 6, 5, 6, 4, 6, 1, 7, 9, 8, 8, 7, 3, 8, 0, 6, 1, 1, 2, 1, 9, 7, 9, 0, 8, 7, 1, 1, 6, 6, 5, 9, 1, 9, 1, 1, 1, 8, 9, 7, 8, 1, 9, 6, 2, 1, 9, 8, 5, 1, 9, 6, 7, 9, 0, 9, 9, 9, 0, 0, 9, 2, 8, 4, 8, 1, 7, 6, 4, 9, 6, 9, 1, 2, 9, 1, 0, 6, 9, 9, 2, 9, 6, 1, 0, 2, 0, 9, 9, 1, 0, 1, 0, 1, 6, 1, 7, 2, 1, 1, 2, 2, 0, 6, 0, 1, 9, 6, 7, 6, 0, 8, 9, 1, 0, 0, 3, 7, 8, 6, 6, 1, 7, 2, 1, 0, 8, 8, 8, 3, 6, 1, 1, 2, 0, 1, 7, 2, 1, 6, 7, 7, 3, 1, 0, 6, 8, 7, 6, 0, 7, 5, 1, 8, 8, 9, 9, 0, 9, 4, 2, 0, 8, 7, 6, 4, 1, 6, 2, 4, 2, 7, 8, 6, 9, 9, 8, 9, 1, 2, 6, 1, 1, 6, 6, 1, 6, 9, 2, 0, 3, 1, 8, 1, 2, 0, 9, 9, 8, 6, 9, 2, 0, 6, 1, 1, 0, 0, 7, 6, 6, 9, 7, 6, 3, 0, 9, 7, 2, 9, 9, 8, 1, 8, 1, 1, 9, 0, 9, 8, 8, 9, 6, 1, 1, 6, 9, 7, 6, 2, 8, 9, 2, 7, 7, 1, 8, 1, 0, 1, 6, 7, 1, 0, 0, 6, 2, 6, 9, 8, 7, 7, 4, 2, 1, 2, 0, 9, 0, 6, 6, 2, 0, 1, 6, 9, 7, 7, 3, 5, 7, 1, 0, 9, 0, 1, 2, 2, 7, 1, 2, 0, 8, 8, 0, 9, 0, 3, 8, 6, 7, 9, 8, 0, 3, 2, 3, 0, 6, 7, 0, 6, 2, 8, 1, 7, 9, 8, 6, 1, 2, 9, 6, 6, 8, 0, 8, 9, 3, 9, 8, 1, 6, 0, 0, 7, 8, 9, 5, 6, 6, 8, 9, 0, 6, 7, 1, 3, 5, 0, 1, 1, 8, 6, 1, 0, 8, 6, 6, 0, 0, 0, 8, 2, 1, 4, 1, 6, 9, 6, 1, 8, 7, 5, 2, 7, 0, 6, 1, 8, 6, 8, 1, 8, 0, 9, 7, 6, 7, 1, 8, 4, 1, 9, 6, 3, 7, 2, 5, 0, 1, 2, 6, 1, 7, 0, 7, 1, 1, 0, 5, 7, 0, 6, 9, 8, 1, 6, 9, 9, 9, 1, 2, 0, 0, 4, 9, 0, 0, 0, 9, 1, 0, 8, 7, 8, 8, 9, 0, 1, 6, 0, 7, 1, 1, 6, 0, 1, 9, 1, 3, 7, 6, 9, 6, 4, 9, 3, 1, 9, 6, 8, 0, 5, 4, 5, 9, 1, 2, 7, 8, 9, 3, 0, 9, 0, 1, 3, 7, 1, 9, 7, 9, 1, 8, 0, 4, 8, 9, 7, 0, 1, 0, 9, 8, 9, 3, 1, 7, 5, 8, 9, 0, 0, 8, 6, 0, 0, 7, 0, 9, 7, 3, 9, 7, 3, 7, 7, 0, 0, 7, 2, 9, 1, 4, 0, 3, 6, 9, 6, 0, 7, 1, 7, 4, 9, 7, 4, 5, 1, 9, 8, 1, 7, 1, 8, 1, 2, 1, 2, 9, 0, 7, 3, 1, 8, 8, 3, 2, 0, 8, 9, 0, 3, 6, 6, 1, 7, 1, 7, 1, 7, 2, 9, 9, 6, 2, 6, 7, 3, 7, 0, 1, 1, 0, 1, 2, 7, 1, 9, 1, 2, 6, 1, 7, 0, 1, 7, 1, 7, 7, 8, 0, 7, 6, 3, 0, 7, 6, 3, 6, 9, 2, 0, 2, 6, 0, 6, 1, 7, 7, 6, 8, 7, 0, 1, 7, 7, 8, 1, 1, 6, 8, 0, 1, 0, 3, 2, 0, 7, 7, 9, 1, 5, 6, 2, 1, 3, 0, 0, 5, 8, 3, 6, 0, 9, 0, 9, 4, 0, 1, 1, 0, 8, 1, 9, 6, 5, 2, 0, 7, 6, 3, 4, 0, 8, 7, 9, 9, 9, 9, 7, 0, 7, 1, 1, 6, 2, 9, 2, 2, 2, 7, 6, 8, 6, 8, 8, 2, 7, 9, 0, 8, 9, 6, 2, 2, 7, 1, 1, 2, 1, 9, 4, 2, 3, 9, 0, 8, 7, 8, 1, 2, 0, 9, 8, 6, 7, 3, 0, 8, 1, 9, 9, 6, 8, 5, 2, 2, 7, 6, 2, 8, 7, 9, 2, 1, 1, 6, 7, 9, 0, 1, 2, 1, 0, 9, 5, 0, 1, 8, 2, 1, 7, 1, 9, 0, 2, 9, 0, 9, 3, 2, 7, 8, 8, 6, 1, 0, 1, 9, 1, 7, 9, 6, 5, 7, 9, 7, 1, 7, 7, 6, 8, 1, 1, 9, 3, 0, 7, 3, 5, 0, 6, 7, 0, 6, 1, 9, 0, 2, 0, 1, 2, 8, 6, 0, 8, 8, 1, 1, 0, 2, 1, 0, 9, 2, 6, 9, 1, 5, 0, 8, 2, 0, 0, 9, 6, 7, 0, 8, 9, 5, 2, 9, 8, 8, 8, 5, 0, 8, 7, 6, 0, 9, 1, 3, 1, 1, 9, 1, 8, 7, 9, 1, 6, 1, 3, 7, 6, 0, 0, 1, 7, 1, 7, 2, 0, 8, 9, 7, 4, 9, 6, 0, 8, 3, 2, 9, 0, 7, 6, 3, 4, 7, 8, 3, 5, 6, 6, 8, 1, 2, 1, 2, 5, 7, 7, 3, 6, 7, 8, 2, 6, 5, 1, 0, 2, 1, 0, 8, 1, 6, 8, 4, 0, 0, 9, 1, 1, 9, 1, 0, 8, 1, 1, 1, 0, 6, 3, 9, 6, 6, 3, 8, 1, 2, 3, 6, 7, 1, 8, 0, 9, 7, 3, 7, 7, 7, 6, 0, 9, 3, 4, 7, 0, 6, 6, 6, 8, 1, 1, 1, 8, 9, 1, 9, 0, 2, 9, 9, 0, 9, 5, 1, 7, 6, 1, 1, 1, 1, 6, 1, 2, 4, 6, 9, 7, 2, 3, 6, 8, 9, 7, 1, 7, 6, 9, 4, 3, 3, 9, 1, 3, 6, 1, 1, 9, 7, 0, 1, 0, 6, 0, 6, 0, 4, 8, 0, 3, 9, 6, 8, 7, 8, 8, 9, 7, 6, 2, 0, 6, 0, 3, 1, 0, 1, 0, 9, 2, 6, 6, 2, 8, 2, 1, 1, 9, 1, 0, 1, 8, 1, 6, 8, 9, 9, 0, 6, 9, 6, 9, 0, 7, 6, 0, 6, 9, 0, 1, 7, 1, 2, 8, 6, 2, 2, 3, 2, 9, 4, 0, 1, 6, 6, 1, 0, 8, 6, 0, 7, 1, 7, 9, 3, 9, 6, 9, 9, 9, 0, 7, 7, 8, 2, 6, 8, 9, 7, 3, 0, 0, 4, 1, 7, 2, 2, 0, 9, 2, 4, 9, 3, 7, 0, 6, 7, 6, 6, 6, 1, 1, 6, 1, 1, 0, 9, 0, 5, 1, 7, 7, 6, 0, 9, 6, 1, 4, 0, 6, 6, 0, 0, 6, 0, 8, 5, 8, 6, 9, 7, 9, 0, 0, 0, 7, 6, 3, 0, 3, 0, 9, 6, 6, 6, 7, 9, 9, 5, 1, 9, 2, 7, 6, 7, 1, 6, 4, 8, 8, 3, 9, 9, 4, 7, 0, 8, 1, 9, 0, 6, 9, 9, 5, 0, 9, 0, 8, 5, 7, 2, 7, 6, 6, 7, 8, 1, 6, 7, 3, 6, 2, 5, 8, 7, 0, 8, 8, 0, 6, 0, 4, 1, 1, 7, 6, 8, 6, 6, 1, 0, 1, 7, 7, 9, 8, 1, 0, 7, 3, 1, 2, 9, 1, 9, 9, 0, 0, 8, 4, 2, 8, 9, 7, 8, 1, 6, 2, 6, 7, 7, 5, 3, 8, 0, 2, 0, 0, 6, 1, 1, 6, 0, 6, 7, 7, 0, 2, 8, 1, 6, 0, 3, 6, 7, 6, 0, 8, 6, 6, 3, 2, 9, 2, 9, 9, 6, 8, 1, 4, 3, 2, 7, 9, 0, 7, 2, 1, 6, 9, 4, 8, 6, 8, 4, 7, 9, 9, 7, 5, 7, 0, 2, 9, 9, 1, 8, 8, 7, 8, 3, 2, 4, 6, 0, 1, 6, 8, 9, 7, 7, 0, 9, 1, 7, 6, 8, 3, 9, 1, 9, 7, 6, 0, 7, 5, 2, 7, 2, 4, 7, 5, 5, 6, 1, 7, 3, 9, 7, 9, 8, 9, 1, 9, 8, 6, 7, 6, 5, 8, 7, 0, 5, 3, 8, 0, 0, 6, 2, 0, 1, 1, 1, 6, 6, 1, 7, 9, 9, 0, 8, 1, 2, 6, 0, 8, 9, 7, 4, 1, 7, 6, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "Y_train_hat = classify_all_images(X_train, mu, sig, -1)\n",
    "\n",
    "print(Y_train_hat) # doit rendre: [0 9 7 ... 6 3 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons bien les classes attendues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie optionnelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5-Matrice de confusion et affichage du r√©sultat des classifications\n",
    "\n",
    "La matrice de confusion est de la forme $C \\times C$ o√π $C$ est le nombre de classe. Les lignes sont les vraies classes, les colonnes sont les classes pr√©dites. Chaque case (i,j) contient le nombre d'images correspondant √† la vraie classe i et √† la pr√©diction j.\n",
    "Si votre classifieur est performant, vous devriez observer des pics sur la diagonale. \n",
    "\n",
    "La fonction `matrice_confusion(Y, Y_hat)` prend en argument un vecteur d'√©tiquettes r√©elles et un vecteur de m√™me taille d'√©tiquettes pr√©dites et retourne la matrice de confusion.\n",
    "\n",
    "Vous devriez obtenir une matrice de la forme:\n",
    "<img src=\"mat_conf_train.png\" title=\"Matrice de confusion\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_all_images(data, liste_params):\n",
    "    \"\"\" Etant donn√©e un tableau d'images et un ensemble de couples de param√®tres tel que d√©termin√© dans les questions\n",
    "        pr√©c√©dents, renvoie un tableau numpy bi-dimensionnel T de taille 10x10 tel que T[i,j] repr√©sente le pourcentage\n",
    "        d'images correspondant en r√©alit√© au chiffre i que le classifieur a class√©es dans la classe j.\n",
    "        @param data: float np.array np.array np.array, tableau des images d'un fichier usps\n",
    "        @param liste_params: (float np.array, np.array) list, liste de couples de param√®tres (liste_mu, liste_sigma_2) \n",
    "                             contenant les param√®tres des lois normales suivies par chaque pixel de l'image\n",
    "        @return T: float np.2D-array, tableau 10x10 repr√©sentant pout T[i,j] le pourcentage d'images i class√© en j\n",
    "    \"\"\"\n",
    "    # ------- T tableau 10x10 des pourcentages d'images i class√©e en j, i et j indices\n",
    "    T = np.zeros((10,10), dtype=float)\n",
    "    \n",
    "    for i in range(len(data)): # i correspond √† la classe des images contenues dans le tableau d'images data[i]\n",
    "        for image in data[i]:\n",
    "            j = classify_image(image, liste_params)\n",
    "            T[i][j] += 1\n",
    "        for j in range(10):\n",
    "            T[i][j] = T[i][j]/len(data[i])\n",
    "        \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_confusion(Y, Y_hat):\n",
    "    \"\"\" Renvoie la matrice de confusion MC.\n",
    "        MC[i,j] contient le nombre d'images i que notre classifieur a class√© en j.\n",
    "        @param Y: int np.array, vraies classes attendues\n",
    "        @param Y_hat: int np.array, classes d√©termin√©es par le classifieur\n",
    "        @return MC: float np.2D-array, tableau 10x10 repr√©sentant pout MC[i,j] le nombre d'images i class√© en j\n",
    "    \"\"\"\n",
    "    MC = np.zeros((10,10), dtype=int)\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        MC[Y[i]][Y_hat[i]] += 1\n",
    "    \n",
    "    return MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de bonne classification: 0.7135976882324611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b49f6b0a90>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALpklEQVR4nO3dyW9d9RnG8efxEEIYxBSKMogEKUApUhvkQiAtC4JUJsGmiyABhUXTVmUUFYJu+AcQggWijRiERASLkAVCEdAyLFDVNMahQGIIiDEQSIAyCASxk7cLGylNYt+T69+PY7/9fiSk2Pfy8mL7m3N9fXyuI0IA8uhpewEAZRE1kAxRA8kQNZAMUQPJ9NUYetwxvbFoYX/xuVtfnlN8JuryrPJfB5IUu0aKz3R/lRwUI6PFZ36rr7UrvvOBbqvyf7FoYb/+9dTC4nN/Ne9nxWdKknp6y8+MPeVn1lTpR5t988p/HUjS6LvvF5/ZN/eE4jMlafSjj4vP3LDn7xPexsNvIBmiBpIhaiAZogaSIWogGaIGkmkUte0LbL9u+03bt9ZeCkD3OkZtu1fSPZIulHSapMttn1Z7MQDdaXKkPlPSmxHxVkTskvSopMvqrgWgW02ini9p79N3to2/73/YXmV70Pbgzk93l9oPwEFqEvWBzi/d75zCiFgdEQMRMTD32AqnXQJopEnU2yTtfQLvAkkf1lkHwFQ1iXqjpCW2F9ueJWmlpMfrrgWgWx1/SysiRm1fK+kpSb2SHoiIzdU3A9CVRr96GRHrJa2vvAuAAjijDEiGqIFkiBpIhqiBZIgaSMY1XkvrSB8TZ3lF8bl/efeF4jMl6fcn/qLKXKCWDfGMvozPDng1UY7UQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyjV5Lqys+4IUOp6TWVT/fuHtZ8ZlLbtpYfGZVsafK2N7j51aZu/vjHcVn9s2fV3ymJI1+uL380EkuAsyRGkiGqIFkiBpIhqiBZIgaSIaogWSIGkimY9S2F9p+zvaw7c22b/ghFgPQnSYnn4xKujkihmwfIelF23+LiC2VdwPQhY5H6ojYHhFD43/+StKwpPm1FwPQnYM6TdT2IklLJW04wG2rJK2SpNmaU2A1AN1o/ESZ7cMlPSbpxoj4ct/bI2J1RAxExEC/Dim5I4CD0Chq2/0aC3pNRKyruxKAqWjy7Lcl3S9pOCLurL8SgKlocqReLulKSefZfmn8n4sq7wWgSx2fKIuIFySV/+VoAFVwRhmQDFEDyRA1kAxRA8nUufCgJff2Fh8bu3cXnylJJ/9pqPjMj/9wVvGZknT8Pf+oMlc95T9fkrTns8+rzO2ZU/6sxd0nHF18piT1fP5F8Zn+ZuLjMUdqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiCZOlcTDSlGR4uPdf+s4jMlKUZHis+sddVPL/1Jlbnx0pYqc91f52WNe340t/jM0aE6H4PPfrOs+MzRx5+Z8DaO1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyjaO23Wt7k+0nai4EYGoO5kh9g6ThWosAKKNR1LYXSLpY0n111wEwVU2P1HdJukXSnonuYHuV7UHbgyP6rshyAA5ex6htXyJpR0S8ONn9ImJ1RAxExEC/6pzvC6CzJkfq5ZIutf2OpEclnWf74apbAehax6gj4raIWBARiyStlPRsRFxRfTMAXeHn1EAyB/X71BHxvKTnq2wCoAiO1EAyRA0kQ9RAMkQNJEPUQDJ1riZqV7nyZ4zsKj5TktTTW3yk+8rPlKT492tV5n530UCVubM/+qbK3N0vv1F8Zu9xxxWfKUnHrJn0ZMyu9I5M/HHlSA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJFPnaqIRVa782XPEEcVnStKer8tf8bLalU8rOWT9YJW5Wx9aWmXukqvKf3x3f/JJ8ZmSpIgfdCZHaiAZogaSIWogGaIGkiFqIBmiBpIhaiCZRlHbPsr2Wtuv2R62fXbtxQB0p+nJJ3dLejIifm17lqQ5FXcCMAUdo7Z9pKRzJV0tSRGxS9LMOl0K+D/S5OH3SZJ2SnrQ9ibb99k+bN872V5le9D24Ii+K74ogGaaRN0n6QxJ90bEUklfS7p13ztFxOqIGIiIgX4dUnhNAE01iXqbpG0RsWH87bUaixzANNQx6oj4SNL7tk8Zf9cKSVuqbgWga02f/b5O0prxZ77fknRNvZUATEWjqCPiJUkDlXcBUABnlAHJEDWQDFEDyRA1kAxRA8nUuZpoJTWu+jk2eHeduTXYdebWuOKlpCVXDVWZu/WvPy8+8+TfbSw+U1Kdz9kkny6O1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kM6MuPNgzu85L5O75tsLrade6mGGlCwS6f1aVuTE6UmXuqTdtLj7z06vPLj5Tko4d+k/xmd76woS3caQGkiFqIBmiBpIhaiAZogaSIWogGaIGkmkUte2bbG+2/artR2zPrr0YgO50jNr2fEnXSxqIiNMl9UpaWXsxAN1p+vC7T9KhtvskzZH0Yb2VAExFx6gj4gNJd0h6T9J2SV9ExNP73s/2KtuDtgdHVOG0SwCNNHn4fbSkyyQtljRP0mG2r9j3fhGxOiIGImKgX3XO0QbQWZOH3+dLejsidkbEiKR1ks6puxaAbjWJ+j1Jy2zPsW1JKyQN110LQLeafE+9QdJaSUOSXhn/d1ZX3gtAlxr9PnVE3C7p9sq7ACiAM8qAZIgaSIaogWSIGkiGqIFkZtTVRGXXmVvryp819PRWGRsju6rMreXbX55WfObRD/2z+ExJ2vHbZcVnjnww8dcBR2ogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBlHRPmh9k5J7za463GSPim+QD0zad+ZtKs0s/adDrueGBFzD3RDlaibsj0YEQOtLXCQZtK+M2lXaWbtO9135eE3kAxRA8m0HfVMe/H6mbTvTNpVmln7TutdW/2eGkB5bR+pARRG1EAyrUVt+wLbr9t+0/atbe3Rie2Ftp+zPWx7s+0b2t6pCdu9tjfZfqLtXSZj+yjba22/Nv4xPrvtnSZj+6bxr4NXbT9ie3bbO+2rlaht90q6R9KFkk6TdLnt8q9NWsaopJsj4seSlkn64zTedW83SBpue4kG7pb0ZEScKumnmsY7254v6XpJAxFxuqReSSvb3Wp/bR2pz5T0ZkS8FRG7JD0q6bKWdplURGyPiKHxP3+lsS+6+e1uNTnbCyRdLOm+tneZjO0jJZ0r6X5JiohdEfF5u1t11CfpUNt9kuZI+rDlffbTVtTzJb2/19vbNM1DkSTbiyQtlbSh3U06ukvSLZL2tL1IBydJ2inpwfFvFe6zfVjbS00kIj6QdIek9yRtl/RFRDzd7lb7aytqH+B90/pna7YPl/SYpBsj4su295mI7Usk7YiIF9vepYE+SWdIujcilkr6WtJ0fn7laI09olwsaZ6kw2xf0e5W+2sr6m2SFu719gJNw4cx37Pdr7Gg10TEurb36WC5pEttv6Oxb2vOs/1wuytNaJukbRHx/SOftRqLfLo6X9LbEbEzIkYkrZN0Tss77aetqDdKWmJ7se1ZGnuy4fGWdpmUbWvse77hiLiz7X06iYjbImJBRCzS2Mf12YiYdkcTSYqIjyS9b/uU8XetkLSlxZU6eU/SMttzxr8uVmgaPrHX18Z/NCJGbV8r6SmNPYP4QERsbmOXBpZLulLSK7ZfGn/fnyNifYs7ZXKdpDXjf7m/JemalveZUERssL1W0pDGfiqySdPwlFFOEwWS4YwyIBmiBpIhaiAZogaSIWogGaIGkiFqIJn/AgIimVP6RWmqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# affichage de la matrice de confusion\n",
    "m = matrice_confusion(Y_train, Y_train_hat)\n",
    "\n",
    "print(\"Taux de bonne classification: {}\".format(np.where(Y_train == Y_train_hat, 1, 0).mean()))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons bien la matrice attendue. Nous remarquons une ligne plus claire le long de la diagonale, correspondant aux cases `(i,i)` de la matrice. Cela nous montre simplement qu'il y a beaucoup de bonnes classifications (beaucoup d'images de classe `i` et class√©es par notre classifieur en `i`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A6- Ensemble d'apprentissage, ensemble de test\n",
    "\n",
    "Dans la proc√©dure que nous avons suivie jusqu'ici, nous avons trich√©. Les m√™mes donn√©es servent √† apprendre les param√®tres et √† √©valuer le mod√®le. Evidemment, le mod√®le est parfaitement adapt√© et les performances sur-estim√©es.\n",
    "\n",
    "Afin de r√©duire ce biais, nous allons maintenant √©valuer les performances sur les donn√©es de test. Les performances devraient √™tre plus basses... Mais plus r√©alistes.\n",
    "\n",
    "Effectuer ces calculs et afficher le taux de bonne classification et la matrice de confusion.\n",
    "\n",
    "**Attention:** il faut donc utiliser les param√®tres appris sur de nouvelles donn√©es sans r√©apprendre des param√®tres sp√©cifiques sinon √ßa ne marche pas\n",
    "\n",
    "Afin de mieux comprendre les erreurs (et de v√©rifier vos connaissances sur numpy): afficher une image de chiffre mal class√©e, son √©tiquette pr√©dite et son √©tiquette r√©elle. \n",
    "Normalement, vous devez retrouver automatiquement que le premier chiffre mal class√© est l'image 10:\n",
    "\n",
    "<img src=\"bad_classif.png\" title=\"exemple d'erreur\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de bonne classification: 0.6907787552948843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14ba050eb50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------- On teste maintenant la performance de notre classifieur avec les images de X_test\n",
    "\n",
    "Y_test_hat = classify_all_images(X_test, mu, sig, -1)\n",
    "\n",
    "# ------- Affichage de la matrice de confusion pour Y_test et Y_test_hat\n",
    "\n",
    "m = matrice_confusion(Y_test, Y_test_hat)\n",
    "\n",
    "print(\"Taux de bonne classification: {}\".format(np.where(Y_test == Y_test_hat, 1, 0).mean()))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous notons que les classifications sont moins bonnes que sur les images de `X_train`, ce √† quoi nous nous attendions. L'observation que nous avions faite auparavant reste cependant valable: la diagonale est plus claire sur la matrice de confusion, ce qui montre que beaucoup d'images sont bien class√©es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autres mod√©lisations possibles pour les images\n",
    "\n",
    "## B. Mod√©lisation par une loi de Bernoulli\n",
    "\n",
    "Soit les indices $i$ donnant les images et les indices $j$ r√©f√©rant aux pixels dans l'image, nous cherchons √† d√©terminer la probabilit√© d'illumination d'un pixel $j$ pour une collection d'image (d'une seule classe, par exemple les $0$).\n",
    "\n",
    "Collection de $0$:\n",
    "$$ X = \\{\\mathbf{x_i}\\}_{i = 1,\\ldots, N}, \\qquad \\mathbf{x_i} \\in \\{0,1\\}^{256}$$\n",
    "\n",
    "Mod√©lisation de la variable de Bernoulli $X_j$, valeur du pixel $j$ en √©criture factoris√©e:\n",
    "$$ p(X_j = x_{ij}) = p_j^{x_{ij}} (1-p_j)^{(1-x_{ij})} = \\left\\{\n",
    "\\begin{array}{ccc}\n",
    "p_j & \\mbox{ si } x_{ij} = 1 \\\\\n",
    "1-p_j & \\mbox{ si } x_{ij} = 0 \\\\\n",
    "\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "Expression de la vraisemblance\n",
    "\n",
    "Maximisation de la vraisemblance $\\Rightarrow$ $\\nabla_{\\theta} \\mathcal L(X, \\theta) = 0$:\n",
    "\n",
    "$$p_j^\\star = \\frac{\\sum_i x_{ij}}{N} $$\n",
    "\n",
    "Intuitif: nombre de $1$ pour le pixel $j$ divis√© par le nombre d'image = pourcentage d'illumination du pixel $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarisation des images pour coller avec l'hypoth√®se de Bernoulli:\n",
    "\n",
    "Xb_train = np.where(X_train>0, 1, 0)\n",
    "Xb_test  = np.where(X_test>0, 1, 0)\n",
    "\n",
    "# affichage d'une image binaire:\n",
    "plt.figure()\n",
    "plt.imshow(Xb_train[0].reshape(16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-1: Ecrire la fonction d'apprentissage des param√®tres qui retourne la matrice theta suivante:\n",
    "\n",
    "$$ \\theta^\\star = \n",
    " \\left[\n",
    " \\begin{array}{ccc}\n",
    "     [p_0^\\star, \\ldots, p_{255}^\\star] & \\mbox{Param√®tres optimaux de la classe 0 au sens du max de vraisembalnce} \\\\\n",
    "     [p_0^\\star, \\ldots, p_{255}^\\star] & \\mbox{Param√®tres optimaux de la classe 1 au sens du max de vraisembalnce} \\\\\n",
    "\\vdots & \\\\\n",
    "     [p_0^\\star, \\ldots, p_{255}^\\star] & \\mbox{Param√®tres optimaux de la classe 9 au sens du max de vraisembalnce} \\\\\n",
    "\\end{array}\n",
    " \\right]\n",
    " $$\n",
    " \n",
    " Il faut ensuite calculer les :\n",
    " $$ \\log p (\\mathbf{x_i} | \\theta^{(c)}) = \\sum_j \\log p(X_j = x_{ij})  = \\sum_j {x_{ij}} \\log p_j + {(1-x_{ij})}\\log(1-p_j)$$\n",
    " \n",
    " Faire passer les $N$ images dans les $C$ mod√®les donne un tableau de la forme :\n",
    " $$ \\log p (X | \\theta) =  \\left[\n",
    " \\begin{array}{cccc}\n",
    " \\log p (\\mathbf{x_0} | \\theta^{(0)}) &  \\log p (\\mathbf{x_0} | \\theta^{(1)}) & \\ldots &  \\log p (\\mathbf{x_0} | \\theta^{(9)}) \\\\\n",
    " & \\vdots & \\\\\n",
    " \\log p (\\mathbf{x_N} | \\theta^{(0)}) &  \\log p (\\mathbf{x_N} | \\theta^{(1)}) & \\ldots &  \\log p (\\mathbf{x_N} | \\theta^{(9)}) \\\\\n",
    "  \\end{array}\n",
    " \\right]\n",
    " $$\n",
    " \n",
    " Chaque ligne donne pour une image sa probabilit√© d'appartenance √† chaque classe $c$.\n",
    " Un argmax par ligne donne une estimation de la classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnBernoulli ( X,Y ):\n",
    "    # votre code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = learnBernoulli ( Xb_train,Y_train )\n",
    "print(theta.shape)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check du r√©sultat pr√©c√©dent:\n",
    "```\n",
    "(10, 256)\n",
    "[[0.00093897 0.00657277 0.03192488 ... 0.02347418 0.00375587 0.        ]\n",
    " [0.         0.         0.         ... 0.00233372 0.         0.        ]\n",
    " [0.01941748 0.05987055 0.13430421 ... 0.27993528 0.20711974 0.11326861]\n",
    " ...\n",
    " [0.06666667 0.16078431 0.2745098  ... 0.         0.         0.        ]\n",
    " [0.01033058 0.05371901 0.1322314  ... 0.01446281 0.00206612 0.        ]\n",
    " [0.0037037  0.0037037  0.01111111 ... 0.00555556 0.00185185 0.        ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-2: Ecrire ensuite une fonction de calcul de la vraisemblance d'une image par rapport √† ces param√®tres\n",
    "\n",
    "**Attention** $log(0)$ n'est pas d√©fini et $log(1-x)$ avec $x=1$ non plus ! \n",
    "La solution √† ce probl√®me est assez simple, il suffit de seuiller les probabilit√©s d'illumination entre $\\epsilon $ et $1-\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logpobsBernoulli(X, theta):\n",
    "    # votre code ici\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpobsBernoulli(X_train[0], theta)\n",
    "# check avec un epsilon = 1e-4 : \n",
    "# array([  95.28940214, -913.86894309, -131.15364866, -104.77977757,\n",
    "#       -209.07303017,  -85.14159392, -122.04368898, -384.11935833,\n",
    "#        -71.06243118, -252.53913188])\n",
    "\n",
    "# ce r√©sultat vous parait-il normal? Qu'est ce qui peut expliquer cette valeur √©tonnante?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-3: Evaluer ensuite vos performances avec les m√™mes m√©thodes que pr√©c√©demment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat = [np.argmax(logpobsBernoulli(Xb_test[i], theta)) for i in range (len(Xb_test))]\n",
    "\n",
    "m = matrice_confusion(Y_test, Y_test_hat)\n",
    "\n",
    "print(\"Taux de bonne classification: {}\".format(np.where(Y_test == Y_test_hat, 1, 0).mean()))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Mod√©lisation des profils de chiffre\n",
    "\n",
    "Comme expliquer dans le TD 2, il est possible de jouer avec les profils des images: chaque image est alors s√©par√©e en 16 lignes et pour chaque ligne, nous mod√©lisons l'apparition du premier pixel allum√© avec une loi g√©om√©trique.\n",
    "Pour plus de simplicit√©, nous vous donnons ci-dessous la fonction de transformation de la base d'image et son application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# modelisation geometrique\n",
    "def transfoProfil(X):\n",
    "    x2 = []\n",
    "    for x in X:\n",
    "        ind = np.where(np.hstack((x.reshape(16, 16), np.ones((16,1))))>0.3)\n",
    "        x2.append( [ind[1][np.where(ind[0] == i)][0] for i in range(16)])\n",
    "    return np.array(x2)\n",
    "\n",
    "Xg_train = transfoProfil(Xb_train)\n",
    "Xg_test  = transfoProfil(Xb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xg_train[0]) # [3 2 2 2 2 2 2 1 1 1 2 1 2 2 3 4]\n",
    "# une image est maintenant repr√©sent√©e par 16 entiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-123: Ecrire les fonctions d'apprentissage des param√®tres et de calcul de la vraisemblance avec cette mod√©lisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnGeom ( X,Y):\n",
    "    # votre code ici\n",
    "    pass\n",
    "    \n",
    "def logpobsGeom(X, theta):\n",
    "    # votre code ici\n",
    "    pass\n",
    "    \n",
    "theta = learnGeom(Xg_train, Y_train)\n",
    "\n",
    "print(logpobsGeom(Xg_test[1], theta))\n",
    "\n",
    "Y_train_hat = [np.argmax(logpobsGeom(Xg_train[i], theta)) for i in range (len(Xg_train))]\n",
    "Y_test_hat  = [np.argmax(logpobsGeom(Xg_test[i], theta)) for i in range (len(Xg_test))]\n",
    "\n",
    "ma = matrice_confusion(Y_train, Y_train_hat)\n",
    "mt = matrice_confusion(Y_test, Y_test_hat)\n",
    "\n",
    "print(\"Taux de bonne classification: {}\".format(np.where(Y_test == Y_test_hat, 1, 0).mean()))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(ma)\n",
    "plt.figure()\n",
    "plt.imshow(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Maximum a posteriori\n",
    "\n",
    "Etant donn√© les distributions non uniformes de classes observ√©es sur le jeu de donn√©e:\n",
    "\n",
    "<img src=\"distr_classes.png\" title=\"Distribution des classes\">\n",
    "\n",
    "Calculer les maxima a posteriori avec les diff√©rentes mod√©lisations et v√©rifier s'il y a un gain en performance avec cette mod√©lisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r√©cup√©ration des probabilit√©s a priori sur les donn√©es d'apprentissage:\n",
    "p= np.histogram(Y_train, np.linspace(-0.5,9.5,11))\n",
    "p = p[0] / p[0].sum()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Fusion de mod√®le\n",
    "\n",
    "R√©ussirez-vous √† fusionner les sorties des mod√®les pr√©c√©dents pour am√©liorer la performance globale en test?\n",
    "* En faisant voter les classifieurs\n",
    "* En pond√©rant ces votes par leurs performances en apprentissage\n",
    "* En fusionnant les vraisemblances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F. Proposer une mod√©lisation en 16 niveaux de gris bas√©es sur une loi multinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
